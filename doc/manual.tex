%%%%%%%%%%%%%%%%%%%%%%            -*-LaTeX-*-
%%%   manual.tex   %%%
%%%%%%%%%%%%%%%%%%%%%%
%%
%%  Date:   06-Mar-2002
%%  Author: wd (Wolfgang.Dobler@kis.uni-freiburg.de)
%%  CVS: $Id: manual.tex,v 1.69 2002-07-24 11:46:03 brandenb Exp $
%%  Description:
%     User manual for the pencil code 
%   Process with:
%     latex manual; makeindex manual; latex manual
%   Macros for files, variables, etc (list loosely adopted from texinfo):
%     \code:     use the line \code{call remove\_file()}
%     \kbd:      type \kbd{M-x comment-region}
%     \key:      press \key{F1}
%     \samp:     \samp{a}, \samp{e}, \samp{i}, \samp{o}, \samp{u}
%     \var:      is determined by \var{ivisc}
%     \env:      this sets \env{CVSROOT}
%     \file:     written to \file{~/tmp/var.dat}
%     \command:  use \command{rm -f *} at your own risk
%     \option:   use CVS with the option \option{-q}
%     \dfn:      A \dfn{definition} is a specification sufficiently obfuscated
%                to be misunderstood 
%     \acronym:  should we call the code \acronym{PROMPT}?
%     \url:      \url{http://www.nowhere.net/second_page.html}
%     \email:    \email{nobody@nowhere.nil}
%

\ifx\pdfoutput\undefined        % not running pdflatex
  \documentclass[12pt,twoside,notitlepage,a4paper]{article}
\else                           % running pdflatex
  \documentclass[pdftex,12pt,twoside,notitlepage,a4paper]{article}
\fi

%\usepackage{url} %(do we not need this; but it's not working anyway)
\usepackage[bookmarks=false]{hyperref}
%\usepackage{german,a4}
%\usepackage[german,british]{babel}
\usepackage[latin1]{inputenc}
%\usepackage[T1]{fontenc}
%\usepackage{ae}                 % To get good PDF with the T1 encoding
\usepackage{newcent,helvet}
\renewcommand{\ttdefault}{cmtt} % Courier is too broad
\usepackage{amsmath}

\usepackage{makeidx}

\usepackage[it,footnotesize]{caption2}
\setlength{\abovecaptionskip}{5pt} % Space before caption
\setlength{\belowcaptionskip}{5pt} % Space after caption

\usepackage[bf,sf,small,nonindentfirst]{titlesec}
\newcommand{\sectionbreak}{\clearpage}
%\titleformat{\subsubsection}{\normalfontitshape}{\thesubsubsection}{.5em}{}
%\titlespacing{\subsubsection}{0pt}{*1}{*-1}
\usepackage{fancyhdr}
\usepackage{fancybox}
\setcounter{tocdepth}{6} % Older versions of fancybox very annoyingly (and
                         % unnecessarily) resets this and make table of
                         % contents disappear

\usepackage{expdlist}
\usepackage{booktabs}
\usepackage{longtable}

\usepackage{fancyvrb}
%\DefineShortVerb{\|}
\usepackage{alltt}
\usepackage{underscore}

\usepackage{graphicx}
\graphicspath{{figs/}}

\usepackage{parskip,a4,vmargin}
\setmargrb{20mm}{25mm}{20mm}{15mm}

\frenchspacing
\sloppy

\makeindex


%%% Page headings
\pagestyle{fancy}
\renewcommand{\sectionmark}[1]{% Don't upcase the section title
  \markright{\thesection.\ #1}}
\fancyhead{}                    % clear header
\fancyhead[LE,RO]{\thepage}
\fancyhead[CE]{\textsc{The pencil code}}
\fancyhead[CO]{\rightmark}
%
\fancyfoot{}

% ---------------------------------------------------------------------- %

%%% Macros

%% Centered table cells for headings
\newcommand{\mcc}[1]{\multicolumn{1}{c}{#1}}

%% Bold face \tt prompts (only works within `alltt' or \tt environment)
\newcommand{\prompt}[1]{{\ttfamily\bfseries{}#1}}

%% Margin and inline notes and remarks
\newcommand\note[1]{\marginpar{\renewcommand{\baselinestretch}{0.8}
        \raggedright\scriptsize\usefont{OT1}{phv}{mc}{n} #1}}
\newcommand{\Note}[1]{\emph{[#1]}}


%% keys, names, paths, files, etc.
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\kbd}[1]{\texttt{\textsl{#1}\/}}
\newcommand{\key}[1]{{\setlength{\fboxsep}{1pt}\ovalbox{\sf #1}}}
\newcommand{\samp}[1]{`\code{#1}'}
\newcommand{\var}[1]{\textsl{#1}\index{#1@\emph{#1}}\/}
\newcommand{\env}[1]{\code{#1}\index{#1@\emph{#1}}}
\newcommand{\file}[1]{`\texttt{#1}'\index{#1@\texttt{#1}}}
\newcommand{\command}[1]{\code{#1}\index{#1}}
\newcommand{\cmd}[1]{\command{#1}}
\newcommand{\option}[1]{`\code{#1}'\index{#1@\emph{`#1'} option}}
\newcommand{\dfn}[1]{\textsl{#1}\index{#1}\/}
%\newcommand{\cite}[1]{}
\newcommand{\acronym}[1]{\textsc{#1}\index{#1}}
%\newcommand{\url}[1]{}
\newcommand{\email}[1]{\code{#1}}

\newcommand{\name}[1]{\textsl{#1}\index{#1}\/}
\newcommand{\Path}[1]{\file{#1}}

%
\newcommand{\bsT}{{\fontencoding{T1}\selectfont{\symbol{92}}}}
\newcommand{\bcks}{\texttt{\symbol{92}}}
\newcommand{\bs}{\bcks}       % Save us creation of a couple of fonts

%% Maths operators
% \newcommand{\arcosh} {\mathop{\rm arcosh}\nolimits}
% \newcommand{\arcoth} {\mathop{\rm arcoth}\nolimits}
\newcommand{\atanh} {\mathop{\rm atanh}\nolimits}
% \newcommand{\sgn}    {\mathop{\rm sgn}\nolimits}
% \newcommand{\grad}    {\mathop{\rm grad}\nolimits}
% \newcommand{\Div}     {\mathop{\rm div}\nolimits}
% \newcommand{\curl}    {\mathop{\rm curl}\nolimits}
% \newcommand{\Laplace} {\mathop{\Delta}\nolimits}
\newcommand{\grad}    {\nabla}
\newcommand{\Div}     {\nabla\cdot}
\newcommand{\curl}    {\nabla\times}
\newcommand{\Laplace} {\nabla^2}
\newcommand{\rot}     {\curl}
\newcommand{\erfc}    {\mathop{\rm erfc}\nolimits}
\newcommand{\erf}     {\mathop{\rm erf}\nolimits}

\newcommand{\vekt}[1] {\mathbf{#1}}
\newcommand{\const}   {\mbox{\rm const}}

%% Maths variables
\newcommand{\Av}            {\vekt{A}}
% \newcommand{\av}            {\vekt{a}}

\newcommand{\Bv}            {\vekt{B}}
% \newcommand{\bv}            {\vekt{b}}

\newcommand{\Cool}          {{\cal C}}
\newcommand{\cs}            {c_{\rm s}}
\newcommand{\csnull}        {c_{{\rm s},0}}

% \newcommand{\Ev}            {\vekt{E}}
% \newcommand{\ev}            {\vekt{e}}
% \newcommand{\ex}            {\ev_{x}}
% \newcommand{\ey}            {\ev_{y}}
% \newcommand{\ez}            {\ev_{z}}

\newcommand{\Fv}            {\vekt{F}}

\newcommand{\gv}            {\vekt{g}}

\newcommand{\Heat}          {{\cal H}}
\newcommand{\Heavi}         {\theta}

\newcommand{\jv}            {\vekt{j}}

\newcommand{\Ra}            {\mathrm{Ra}}
\newcommand{\Reynolds}      {\mathrm{Re}}
\newcommand{\Rm}            {\mathrm{Rm}}

\newcommand{\uv}            {\vekt{u}}

% \newcommand{\Vol}           {{\cal V}}
\newcommand{\vA}            {v_{\rm A}}

\newcommand{\xv}            {\vekt{x}}

\newcommand{\zerovect}      {\vekt{0}}

\newcommand{\bra}[1]{\langle #1\rangle}
\newcommand{\Eq}[1]{Eq.~(\ref{#1})}
\newcommand{\nab}{\mbox{\boldmath $\nabla$} {}}
\newcommand{\dd}{{\rm d} {}}

% ---------------------------------------------------------------------- %

\title{{\sffamily\bfseries Installing and Using the High-Order Pencil MPI code}}
%\subtitle{A very preliminary manual}
\author{Wolfgang Dobler \& Axel Brandenburg}
\date{\today,~ $ $Revision: 1.69 $ $}

% ====================================================================== %

\begin{document}
\pagestyle{empty}

%\maketitle

\begin{titlepage}
  \begin{center}

  \large

  \vspace*{3cm}

  {\Large\sffamily\bfseries PENCIL--MPI: A High-Order MPI code for MHD Turbulence}

  \vspace{0.5cm}

  {\sffamily Documentation and Results of Test Problems}

  \vspace{1.5cm}

  {Wolfgang Dobler \& Axel Brandenburg}


  \vspace{2cm}

  \emph{\today,~ $ $Revision: 1.69 $ $}


\end{center}

\end{titlepage}


\newpage
\mbox{}
\vfill

Copyright \copyright{} 2001,2002 Wolfgang Dobler \& Axel Brandenburg
\bigskip

Permission is granted to make and distribute verbatim copies of
this manual provided the copyright notice and this permission notice
are preserved on all copies.

Permission is granted to copy and distribute modified versions
of this manual under the conditions for verbatim copying,
provided that the entire resulting derived work is distributed under the
terms of a permission notice identical to this one.


\clearpage
\pagestyle{plain}
\pagenumbering{roman}

\section*{Foreword}

This code was originally developed at the Turbulence Summer School of the
Helmholtz Institute in Potsdam (2001).
While some SPH and PPM codes for hydrodynamics and magnetohydrodynamics
are publicly available, this does not generally seem to be
the case for higher order finite-difference or spectral codes.
Having been approached by people interested in using our code, we have
decided to make it as flexible as possible and as user-friendly as seems
reasonable, and to put it onto a public \name{CVS} repository.
The code can certainly not be treated as a black box (no code can), and in
order to solve a new problem in an optimal way, you will need to find your
own set of parameters, in particular you may need to add or increase
artificial viscosity and diffusivities.

The code is primarily designed to deal with weakly compressible turbulent
flows, which is why we use high-order first and second derivatives.
To achieve good parallelization, we use explicit
(as opposed to compact) finite differences.
Typical scientific targets include driven MHD turbulence in a periodic box,
convection in a slab with non-periodic upper and lower boundaries,
a convective star embedded in a fully nonperiodic box, accretion disc
turbulence in the shearing sheet approximation, etc.

Magnetic fields are implemented in terms of the magnetic vector potential
to ensure that the field remains solenoidal (divergence-free).
At the same time, having the magnetic
vector potential readily available is a tremendous advantage if
one wants to monitor the magnetic helicity, for example.
The code is therefore particularly well suited for all kind of
dynamo problems.

The code is non-conservative; thus, conserved quantities should only be
conserved up to the discretization error of the scheme (not the machine
accuracy).
There is no guarantee that a conservative code is more accurate with
respect to quantities that are not explicitly conserved, such as entropy.
Another important quantity that is (to our knowledge) not strictly
conserved by ordinary flux conserving schemes is \name{magnetic helicity}.

There are currently no plans to implement adaptive mesh refinement
into the code, which would cause major technical complications.
Given that turbulence is generically space-filling, local refinement
to smaller scales would often not be very useful anyway.
On the other hand, in some geometries
turbulence may well be confined to certain regions in space, so one
could indeed gain by solving the outer regions with fewer points.

In order to be cache-efficient, we solve the equations along
\name{pencils} in the $x$ direction.
One very convenient side-effect is that auxiliary and derived variables
use very little memory, as they are only ever defined on one pencil.
The domain can be tiled evenly in the $y$ and $z$ directions.
On multiprocessor computers, the code uses \name{MPI}
(Message Passing Interface) calls to communicate between processors.
An easy switching mechanism allows the user to run the code on a machine
without MPI libraries (e.g.~a notebook computer).
Ghost zones are used to implement boundary conditions on physical and
processor boundaries.

The code achieves a high level of flexibility by encapsulating individual
physical processes and variables in individual \name{modules}, which can
be switched on or off in the file \file{Makefile.local} in the local
\file{src} directory.
In order to avoid excessive use of preprocessor directives, we were lead
to create one dummy module for each physics module.
For nonmagnetic hydrodynamics, e.g., one will use the module
\file{nomagnetic.f90}:
\begin{Verbatim}
  MAGNETIC=nomagnetic
\end{Verbatim}
while for MHD simulations, \file{magnetic.f90} will be used:
\begin{Verbatim}
  MAGNETIC=magnetic
\end{Verbatim}
Note that the term \name{module} as used here is not identical to Fortran
modules: both \file{magnetic.f90} and \file{nomagnetic.f90} define an F90
module named \emph{Magnetic} --- this is the basis of the switching
mechanism we are using.

Input parameters (in the files \file{start.in}, \file{run.in}) can be
changed without recompilation.
What is more, one can change the list of variables for monitoring
(diagnostic) output on the fly, and there are mechanisms for making the
code reload new parameters or exit gracefully.

The requirements for using the Pencil-MPI code are modest: you can use it
on any Unix system with a F90/F95 compiler. If you have \name{IDL} as
well, you will be able to visualize the results, but other tools such as
\name{DX} (OpenDX, data explorer) can also be used.

\bigskip

If you want to make creative use of the code, this manual will contain far
too little information.
Its major aim is to give you an idea of the way the code is organized, so
you can more efficiently \emph{read the source code}.
For many enhancements you would like to add, you can follow the
lines of other variables, functions, diagnostics, equations etc.~ which we
have already implemented.
Remember: \cmd{grep} is one of your best friends when you want to
understand how certain variables or functions are used in the code.


\bigskip

We will be happy to include user-supplied changes and updates to the code
in future releases and welcome any feedback.

\vspace{5mm}
%\noindent
\url{Wolfgang.Dobler@kis.uni-freiburg.de}\hfill Freiburg\\
\url{Axel.Brandenburg@nordita.dk}\hfill Copenhagen

\section*{Acknowledgments}

Many people have contributed in different ways to the development of this
code. We thank first of all {\AA}ke Nordlund (Copenhagen Observatory)
and Bob Stein (University of Michigan) who introduced us to the idea of
using high-order schemes in compressible flows and who taught us a lot
about simulations in general.

The shearing sheet approximation and the flux limited diffusion approximation
were implemented by Nils Haugen (University of Trondheim).

Vladimir Pariev (University of Rochester) contributed to the development
and testing of the potential field boundary condition.

\tableofcontents
\clearpage
\pagestyle{fancy}
\pagenumbering{arabic}


% ====================================================================== %

\section{System Requirements}

To use the code, you will need the following:

\begin{enumerate}

  \item Absolutely needed:
    \begin{itemize}
    \item F90 or F95 compiler
    \end{itemize}

\item Used heavily (if you don't have one of these, you will need to
  adjust many things manually):
  \begin{itemize}
  \item a \name{Unix}-type system with \name{make} and \name{csh}
  \item \name{Perl} (remember: if it doesn't run Perl, it's not a
    computer)
  \end{itemize}

\item The following are dispensable, but enhance functionality in one ore
  the other way:
  \begin{itemize}
  \item an \name{MPI} implementation (for parallelization on
    multiprocessor systems)
  \item a \name{C} compiler (for some debugging functionality)
  \item \name{DX} alias \name{OpenDX} or \name{data explorer} (for
    visualization of results)
  \item \name{IDL} (for visualization of results; the 7-minute demo
    license will do for many applications)
  \end{itemize}

\end{enumerate}

If you like the exotic and get the code running in a \name{Cygwin}
environment, please let us know.


% ====================================================================== %

\section{Obtaining the Code}

There are two ways to obtain and install the code: If you want to use a
stable release, you can download it as a tarball and unpack it.
If you prefer to use the latest experimental version,
you can access it via anonymous CVS access.

% ---------------------------------------------------------------------- %

\subsection{Obtaining and unpacking the tarball}

\begin{enumerate}
\item Download the tarball from
  \path{http://www.nordita.dk/~brandenb/pencil-code/download/pencil_modular.tgz}
\item Put it into a convenient directory and unpack it:
  \begin{alltt}
  \prompt{unix> } mv pencil_modular.tgz somewhere/; cd somewhere
  \prompt{unix> } gunzip pencil_modular.tgz
  \prompt{unix> } tar xf pencil_modular.tar \
  \end{alltt}
\item {}[Optional:] Rename the directory \file{pencil_modular} to \file{mhd}
  if you want to be consistent with the notation used throughout this
  manual.
\end{enumerate}

% ---------------------------------------------------------------------- %

\subsection{Obtaining the code via anonymous CVS}

\begin{enumerate}

\item Get a \name{CVS} client from \url{http://www.cvshome.org/} and
  install it (on any machine where you want to run the code).
  Alternatively, just copy the executable from a binary compatible
  machine.

\item Get the password for anonymous \name{CVS} access to the pencil code
\footnote{In future, this should work automatically, to allow new users
to just look into the code without hassle}

\item Set your environment variable \env{CVSROOT} (you probably want to
  put this into your \file{.cshrc} or \file{.profile} setup files):
  \begin{alltt}
  \prompt{csh> } setenv CVSROOT \bs
          :pserver:anonymous@norserv.nordita.dk:/home/brandenb/CVS \
  \end{alltt}
  or (if you are running Bourne shell or bash)
  \begin{alltt}
  \prompt{sh> } CVSROOT=:pserver:anonymous@norserv.nordita.dk:/home/brandenb/CVS
  \prompt{sh> } export CVSROOT \
  \end{alltt}

\item Log in:
  \begin{alltt}
  \prompt{unix> } cvs login
  cvs password: ........ \
\end{alltt}
(you only need to do this once; your CVS password is saved in the file
\file{.cvspass} in your home directory)

\item Go to wherever you want the code:
  \begin{alltt}
  \prompt{unix> } cd \file{somewhere} \
  \end{alltt}
  and check the code out:
  \begin{alltt}
  \prompt{unix> } cvs checkout pencil-code \
  \end{alltt} 
  This creates a subdirectory \file{somewhere/pencil-code} and populates it with
  the pencil-code's subdirectories.

\end{enumerate}


% ---------------------------------------------------------------------- %

\subsection{Updating via CVS}

Independent from how you installed the code in the first place (tarball or
CVS), you can update your version via CVS.
If you have done nontrivial alterations to your version of the code, you
ought to be careful about upgrading: although CVS is the optimal tool for
distributed programming, conflicts are quite likely, since we are going to
touch many parts of the code while we develop it further.
Thus, despite the fact that the code is under CVS, you should probably
back up your changes before upgrading.

Here is the upgrading procedure:
\begin{enumerate}
\item Go to the top directory of the code:
  \begin{alltt}
  \prompt{unix> } cd \file{somewhere/mhd} \
  \end{alltt}
\item Run \cmd{cvs update}:
  \begin{alltt}
  \prompt{unix> } cvs -q update -dP \
  \end{alltt}
  (the option \option{-q} means `somewhat' quiet \option{-d} checks out
  new directories, and \option{-P} removes empty directories)
\item Fix any conflicts you encounter and make sure the examples are still
  working.
\end{enumerate}

% ---------------------------------------------------------------------- %

\subsection{Getting older versions}

You may find that the latest CVS version of the code produces errors.
If you have reasons to believe that this is due to changes introduced on
31 June 2002 (to give an example), you can check out the version prior to
this by:
\begin{enumerate}
\item Go to the top directory of the code:
  \begin{alltt}
  \prompt{unix> } cd \file{somewhere/mhd} \
  \end{alltt}
\item Run \cmd{cvs update}:
  \begin{alltt}
  \prompt{unix> } cvs up -D "30 Jun 2002"\
  \end{alltt}
\end{enumerate}


% ====================================================================== %

\section{Getting Started}
\label{S-getting-started}

To get yourself started, you should run one or several examples which are
provided in one of the runs/sample subdirectories.

You will only be able to fully assess the numerical solutions if you
visualize them with \name{IDL}, \name{DX} or other tools (see
Sect.~\ref{S-IDLroutines}).

% ---------------------------------------------------------------------- %

\subsection{Setup}

\subsubsection{Environment settings}

The functionality of helper scripts and IDL routines relies on a few
environment variables being set correctly.
The simplest way to achieve this is to go to the top directory of the code
(we will assume here that it is called \file{pencil}) and source one of
the two scripts \file{sourceme.csh} or \file{sourceme.sh} (depending on
the type of shell you are using):
\begin{alltt}
  \prompt{csh> } cd pencil-code
  \prompt{csh> } source ./sourceme.csh
\end{alltt}
for \name{tcsh} or \name{csh} users; or
\begin{alltt}
  \prompt{sh> } cd pencil-code
  \prompt{sh> } . ./sourceme.sh
\end{alltt}
for users of \name{bash}, \name{Bourne shell}, or similar shells.
You should get output similar to
\begin{alltt}
  PENCIL_HOME = </home/dobler/f90/pencil-code>
  Adding /home/dobler/f90/pencil-code/bin to path
\end{alltt}
Apart from the \env{PATH} variable, the environment variable
\env{IDL_PATH} has been set to something like
\texttt{./idl:../idl:+\$PENCIL_HOME/bin:./tmp:<IDL_DEFAULT>} .


\subsubsection{Linking scripts and source files}

With your environment set up correctly, you can now go to the directory
you want to work in and set up subdirectories and links.
This is accomplished by the script \file{lnsrc}, which is located in
\file{\$PENCIL_HOME/bin} and is thus now in your executable path.

For concreteness, let us assume you want to use \file{samples/conv-slab}
as your \dfn{run directory}, i.\,e~you want to run a three-layer slab model
of solar convection.
You then do the following:
\begin{alltt}
  \prompt{unix> } cd samples/conv-slab
  \prompt{unix> } lnsrc
  {\sl{}[Output]}
\end{alltt}
The script has linked a number of scripts from \file{\$PENCIL_HOME/bin},
generated a directory \file{src} for the source code and linked the
Fortran source files (plus a few more files) from \file{\$PENCIL_HOME/src}
to that directory:
\begin{alltt}
  \prompt{unix> } ls
  {\sl{}[Output]}
\end{alltt}


\subsubsection{Localizing the Makefile}

This step requires some input from you, but you only have to do this once
for each machine you want to run the code on.
See Sect.~\ref{adapt-mkfile} for a description of the steps you need to
take here.


\subsubsection{Running \cmd{make}}

Next, you run \cmd{make} in the \file{src} subdirectory of your run
directory.
Since you are using one of the predefined test problems, the settings in
\file{src/Makefile.local} and \file{src/cparam.local} are all reasonable,
and you just do
\begin{alltt}
  \prompt{unix> } cd src
  \prompt{unix> } make \
\end{alltt}
If you have set up the compiler flags correctly, compilation should
complete successfully; don't forget to return to the run directory,
\begin{alltt}
  \prompt{unix> } cd .. \
\end{alltt}


\subsubsection{Choosing a data directory}

The code will write data like snapshot files to the subdirectory
\file{tmp} of the run directory.
Since this will involve a large volume of IO-operations (at least for
large grid sizes), one will normally try to avoid writing the data via
NFS.
The recommended way to set up a \file{tmp} data directory is to generate
a corresponding directory on the local disc of the computer you are
running on and (soft-)link it to \file{./tmp}.
Even if the link is part of an NFS directory, all the IO operations will
be local.
E.\,g.~if you have a local disc \file{/scratch}, you can do the following
\begin{alltt}
  \prompt{unix> } mkdir -p /scratch/\$USER/pencil-data/samples/conv-slab
  \prompt{unix> } ln -s /scratch/\$USER/pencil-data/samples/conv-slab ./tmp \
\end{alltt}

Even if you don't have an NFS-mounted directory (say, on you notebook
computer), it is probably still a good idea to have code and data well
separated by a scheme like the one described above.


\subsubsection{Running the code}

You are now ready to start the code:
\begin{alltt}
  \prompt{unix> } start.csh\small
  Linux cincinnatus 2.4.10-4GB #1 Tue Sep 25 12:33:54 GMT 2001 i686 unknown
  Non-MPI version
  Thu Jul 18 16:25:20 CEST 2002
     src/start.x
  CVS: hydro.f90          v. 1.48         (dobler    ) 2002/07/19 10:26:01
  {\sl{}[\ldots]}
  CVS: start.in           v. 1.2          (dobler    ) 2002/07/19 10:23:57
   mx,my,mz=          38          38          38
   
   uu: up-down
   piecewise polytropic vertical stratification (lnrho)
   init_lnrho: cs2bot,cs2top=   1.450000      0.3333330    
   piecewise polytropic vertical stratification (ss)
   Note: mpoly{1,2} override hcond{1,2} to    2.000000      0.5000000    
   
  0.060u 0.000s 0:00.24 25.0\%     0+0k 0+0io 126pf+0w
  
  Fri Jul 19 13:04:38 CEST 2002
\end{alltt}
This runs \file{src/start.x} to construct an initial condition based on
the parameters set in \file{start.in}.
This initial condition is stored in \file{tmp/proc0/var.dat} (and in
\file{tmp/proc1/var.dat}, etc. if you run the multiprocessor version).

% ---------------------------------------------------------------------- %
\begin{figure}[hbtp]
  \centering
  \includegraphics%
    [width=1\textwidth,keepaspectratio]%
    {pvert0}
  \caption{Initial state of the three-layer convection model in
    \file{samples/conv-slab}.
    Shown are (from left to right) density $\varrho$, vertical velocity
    $u_z$, entropy $s/c_p$ and temperature $T$ as functions of the
    vertical coordinate $z$ for about ten different vertical lines in the
    computational box.
    The dashed lines denote domain boundaries:
    $z<-0.68$ is the lower ghost zone (points have no physical significance);
    $-0.68<z<0$ is a stable stratified layer ($ds/dz>0$);
    $0<z<1$ is the unstable layer ($ds/dz<0$);
    $1<z<1.32$ is the isothermal top layer;
    $z>1.32$ is the upper ghost zone (points have no physical significance).
  }
  \label{Fig-pvert0}
\end{figure}
% ---------------------------------------------------------------------- %

If you have IDL, you can visualize the initial state with (see
Sec.~\ref{S-IDLroutines} for details)
\begin{alltt}
  \prompt{unix > } idl
  \prompt{IDL >  } .r start
  \prompt{IDL >  } .r r
  \prompt{IDL >  } .r thermo
  \prompt{IDL >  } .r pvert \
\end{alltt}
The result should look like in Fig.~\ref{Fig-pvert0}, apart from details
of the vertical velocity field, which is random.

\bigskip

Now we run the code:
\begin{alltt}
  \prompt{unix> } run.csh
\end{alltt}
This runs \file{src/run.x} and carries out \var{nt} time steps, where
\var{nt} and other run time parameters are specified in \file{run.in}.
On a decent PC (1.7\,GHz), 1000 time steps take about 3 minutes.

The relevant part of the code's output looks like\\
\begin{minipage}{1\textwidth}
\bigskip
\begin{small}
\begin{alltt}
  ---it------t--------dt--------urms------umax------rhom------ssm-------dtc----
       0     0.00  7.603E-03   0.00633   0.09560   14.4708  -0.44601  4.21E-01
      50     0.38  7.596E-03   0.00599   0.04438   14.4707  -0.44753  4.21E-01
     100     0.76  7.581E-03   0.00679   0.03343   14.4704  -0.44775  4.20E-01
     150     1.13  7.254E-03   0.00647   0.02703   14.4701  -0.44667  4.02E-01
     200     1.49  7.119E-03   0.00498   0.01818   14.4692  -0.44667  3.95E-01
     250     1.85  7.103E-03   0.00409   0.01724   14.4692  -0.44729  3.94E-01
     300     2.20  7.048E-03   0.00381   0.01391   14.4700  -0.44763  3.91E-01
     350     2.55  7.047E-03   0.00362   0.01344   14.4702  -0.44770  3.91E-01
     400     2.90  6.948E-03   0.00321   0.01262   14.4702  -0.44771  3.85E-01
     450     3.24  6.902E-03   0.00333   0.01419   14.4697  -0.44795  3.83E-01
     500     3.59  6.938E-03   0.00324   0.01327   14.4690  -0.44792  3.85E-01
     550     3.93  6.853E-03   0.00292   0.01326   14.4685  -0.44760  3.80E-01
     600     4.27  6.795E-03   0.00284   0.01267   14.4685  -0.44814  3.77E-01
     650     4.62  6.913E-03   0.00330   0.01107   14.4688  -0.44960  3.83E-01
     700     4.96  6.983E-03   0.00276   0.01323   14.4689  -0.45079  3.87E-01
     750     5.31  6.977E-03   0.00347   0.01322   14.4687  -0.45108  3.87E-01
     800     5.66  6.882E-03   0.00469   0.01428   14.4683  -0.45043  3.81E-01
     850     6.00  6.747E-03   0.00483   0.01424   14.4680  -0.44953  3.74E-01
     900     6.33  6.669E-03   0.00463   0.01382   14.4678  -0.44917  3.70E-01
     950     6.67  6.686E-03   0.00488   0.01599   14.4679  -0.44937  3.71E-01
\end{alltt}
\end{small}
\bigskip
\end{minipage}
and lists
\begin{enumerate}
\item the number \var{it} of the current time step; 
\item the time \var{t};
\item the time step \var{dt};
\item the rms velocity \var{urms}$=\sqrt{\left<\uv^2\right>}$;
\item the maximum velocity \var{umax}$=\max |\uv|$;
\item the mean density \var{rhom}$=\left<\varrho\right>$;
\item the mean entropy \var{ssm}$=\left<s\right>/c_p$;
\item the time step in units of the acoustic Courant step
  \var{dtc}$=\delta t/({\cs}_0\,\delta x_{\rm min})$.
\end{enumerate}
The entries in this list can be added, removed or reformatted in the file
\file{print.in}, see Sec.~\ref{diagnostic-IO}.

To visualize the resulting state, run
\begin{alltt}
  \prompt{IDL >  } .r r
  \prompt{IDL >  } .r pvert \
\end{alltt}
and you should obtain something similar to Fig.~\ref{Fig-pvert1}, which
corresponds to the state after 1000 time steps.

% ---------------------------------------------------------------------- %
\begin{figure}[hbtp]
  \centering
  \includegraphics%
    [width=1\textwidth,keepaspectratio]%
    {pvert1}
  \caption{Like in Fig.~\ref{Fig-pvert0}, but after 1000 time steps at
    time $t=7.0$.
    The dashed lines represents the initial condition.
  }
  \label{Fig-pvert1}
\end{figure}
% ---------------------------------------------------------------------- %

For the evolution of velocity and the state at later times, see
Sect.~\ref{S-ref-data} in the Appendix.


\paragraph{Note:}
If you want to run the code with \name{MPI}, you will probably need to
adapt \file{getconf.csh}, which defines the commands and flags used to
run MPI jobs (and which is sourced by the scripts \file{start.csh} and
\file{run.csh}).
Try
\begin{alltt}
  csh -v getconf.csh
  {\sl or}
  csh -x getconf.csh
\end{alltt}
to see how \file{getconf.csh} makes its decisions.


% ---------------------------------------------------------------------- %

\subsection{A second test}

Now you are ready to compile and run a simple example (periodic,
isothermal, non-forced MHD) where the physics is already nontrivial.

\subsubsection{Interlocked flux rings}

\begin{alltt}
  \prompt{unix> } cd somewhere/mhd
  \prompt{unix> } source sourceme.csh \quad\#(to put pencil-code/bin into your path)
  \prompt{unix> } cd runs/sample/rings
  \prompt{unix> } lnsrc \quad\#(from \file{../../../bin}, which by now should be in your path)
  \prompt{unix> } cd src
  \prompt{unix> } make
  \prompt{unix> } cd ..
  \prompt{unix> } mkdir tmp \quad{\sl\# (or [better] link directory on local disc to \file{tmp})}
  \prompt{unix> } ./start.csh
  \prompt{unix> } ./run.csh
\end{alltt}

The output should look like \ldots

\vspace{5cm}

EXPLAIN: isotrop1, plan to set-up vortex rings as initial condition,
without magnetic fields etc.

% ---------------------------------------------------------------------- %

\subsection{Other test problems}

1-D sound waves and shock tube tests, interlocked pair of flux rings, stably stratified atmosphere.

For 1-D and 2-D tests, one can put \var{nxgrid}=1, \var{nygrid}=1,
and/or \var{nzgrid}=1.

% ====================================================================== %

\section{Code structure}

% ---------------------------------------------------------------------- %

\subsection{Directory tree}

 % ---------------------------------------------------------------------- %
\begin{figure}[hbtp]
  \centering
  \includegraphics%
    [width=0.9\textwidth,height=0.65\textheight,keepaspectratio]%
    {struct}
  \caption{The basic structure of the code}
  \label{Fig-Structure}
\end{figure}
% ---------------------------------------------------------------------- %

The overall directory structure of the code is shown in
Fig.~\ref{Fig-Structure}.
Under \file{pencil-code}, there are currently the following
files and directories:
\begin{verbatim}
  CVS/    bin/  bugs/         doc/
  dx/     idl/  runs/         src/
  README  TODO  sourceme.csh  sourceme.sh
\end{verbatim}

Almost all of the source code is contained in the directory \file{src/},
but in order to encapsulate individual applications, the code is compiled
separately for each run in a local \file{src} directory below the
individual run directory, like e.g.~\file{runs/gravz/vconv1/src}.

The directory \file{runs} contains individual run directories, grouped in
classes (like \file{spher} for spherical calculations, or \file{kinematic}
for kinematic dynamo simulations.
The current list of classes is
\begin{verbatim}
  gravz/      forced/     OLD/      old/
  buoy_tube/  kinematic/  1d-tests/ rings/
\end{verbatim}
The directory \file{forced/} contains some forced turbulence runs (both
magnetic and nonmagnetic);
\file{gravz/} contains runs with vertical gravity;
\file{rings/} contains decaying MHD problems (interlocked flux rings as
initial condition, for example);
and \file{kinematic/} contains kinematic dynamo problems where the
hydrodynamics is turned off entirely.
The file \file{runs/README} will contain an up-to-date list and
short description of the individual classes.

The subdirectory \file{src} of each run directory contains a few local
configuration files (currently these are \file{Makefile.local} and
\file{cparam.local}, together with links to
all the \file{.f90} and \file{.c} files and the \file{Makefile} in the top
\file{src} directory (these links are set up by the script \cmd{lnsrc}.

General purpose visualization routines for \name{IDL} or \name{DX} are in the
\file{idl} and \file{dx} directories, respectively.

The directory \file{doc} contains this manual; \file{bin} a number of
utility scripts (\name{csh} and \name{Perl}).
The \file{CVS} directory is used (you guessed it) by \name{CVS}, and is
not normally directly accessed by the user.
\file{bugs}, finally is used by us for internal purposes.

\bigskip

The files \file{sourceme.csh} and \file{sourceme.sh} will set up some
environment variables --- in particular \var{PATH} --- and aliases/shell
functions for your convenience.
If you do not want to source one of these files, you need to make sure
your \name{IDL} path is set appropriately (provided you want to use
\name{IDL}, that is) and you will need to address the scripts from
\file{bin} with their explicit path name.


% ----------------------------------------------------------------------------- %

\subsection{Basic concepts}

\subsubsection{Data access in pencils}
\index{pencil design}

Unlike the CRAY computers that dominated supercomputing in the 80s and
early 90s, all modern computers have a cache that constitutes a significant
bottleneck for many codes.
This is the case if large three-dimensional arrays are constantly used
within each time step, which has the obvious advantage of leading to
conceptual simplicity of the code and using F90 array syntax as much as
possible.
A more  cache-efficient way of coding is to calculate an entire time step
(or substep of a multi-stage time-stepping scheme) only
along a one-dimensional pencil of data within the numerical grid.
This technique was popular on vector computers, but it is also quite
efficient for modern RISC processors:
On Linux PCs and SGI workstations, for example, we have found a speed-up
by about 60\%{} in some cases.
An additional advantage is a drastic reduction in temporary storage for
auxiliary variables within each time step.


\subsubsection{The 2$N$-scheme}
\index{2N-scheme}

For time stepping, higher-order schemes are necessary in order to reduce
the amplitude error of the scheme and to allow longer time steps. Usually
such schemes require large amounts of memory.
However, we here use the memory-effective $2N$-schemes that require only
two sets of variables to be held in memory.
Such schemes work for
arbitrarily high order, although not all Runge-Kutta schemes can be
written as $2N$-schemes \cite{2Nstorage,SH88}.
Consider the ordinary differential equation (ODE)
\begin{equation}
  \dot{u} = F(u,t) \; ,
\end{equation}
which can also be used as a prototype for a system of ODEs to be solved,
like the ones obtained by spatial discretization of PDEs.
The $2N$-schemes construct an approximation to the solution
\begin{equation}
  u^{(n)} \equiv u(t_n)
\end{equation}
according to the iterative procedure
\begin{equation}
  w_i=\alpha_i w_{i-1}+\delta t\,F(u_{i-1},t_{i-1}),
\end{equation}
\begin{equation}
  u_i=u_{i-1}+\beta_i w_i.
\label{iterform0}
\end{equation}
For a three-step scheme we have $i=1,...,3$.
In order to advance the variable $u$ from $u^{(n)}$ at time $t^{(n)}$
to $u^{(n+1)}$ at time $t^{(n+1)}=t^{(n)}+\delta t$ we set in \Eq{iterform0}
\begin{equation}
  u_0=u^{(n)}
  \quad\mbox{and, after the last step,}\quad
  u^{(n+1)}=u_3,
\end{equation}
with $u_1$ and $u_2$ being intermediate steps. In order to be able to
calculate the first step, $i=1$, for which no $w_{i-1}\equiv w_0$ exists,
we have to require $\alpha_1=0$. Thus, we are left with 5 unknowns,
$\alpha_2$, $\alpha_3$, $\beta_1$, $\beta_2$, and $\beta_3$. Three
conditions follow from the fact that the scheme be third order, so we
have to have two more conditions. One possibility is to choose the
fractional times at which the right hand side is evaluated, for
example $(0,1/3,2/3)$ or even $(0,1/2,1)$.
%wd: Don't see the point of the following: 
% In the latter case the right hand
% side is evaluated twice at the same time. It is therefore some sort of
% predictor-corrector scheme.
Yet another possibility is to require that
inhomogeneous equations of the form $\dot{u}=t^n$ with $n=1$ and 2 are
solved exactly.
The corresponding coefficients are listed in Table~\ref{T-2N-RK3} and compared
with those given by Williamson \cite{2Nstorage}. In practice all of them
are about equally good when it comes to real applications, although
we found the first one in Table~\ref{T-2N-RK3} (`symmetric') marginally better in some
simple test problems where an analytic solution was known.

\begin{table}[htb]
  \centering
  \caption{
    Coefficients for different $2N$-type third-order Runge-Kutta
    schemes.
    The coefficients $c_i$ (which are determined by the $\alpha_i$,
    $\beta_i$) give the time for each substep,
    $t_i = t_0 + c_i \delta t$
    }\label{T-2N-RK3}
  \vspace{12pt}
  \begin{tabular}{l@{\quad}ccc@{\quad}cc@{\quad}ccc}
    \toprule
    scheme            & $c_1$
                            & $c_2$
                                    & $c_3$
                                              & $\alpha_2$
                                                         & $\alpha_3$
                                                                    & $\beta_1$
                                                                            &$\beta_2$
                                                                                    & $\beta_3$\\
    \midrule
    symmetric         & $0$ & $1/3$ & $2/3$   &  $-2/3$  &   $-1$   & $1/3$ &  $1$  & $1/2$ \\
    {}[predictor/corrector]
                      & $0$ & $1/2$ & $1$     &  $-1/4$  &  $-4/3$  & $1/2$ & $2/3$ & $1/2$ \\
    inhomogeneous     & $0$ & $15/32$ & $4/9$ & $-17/32$ & $-32/27$ & $1/4$ & $8/9$ & $3/4$ \\
    Williamson (1980) & $0$ & $4/9$ & $15/32$ &  $-5/9$  &$-153/128$& $1/3$ &$15/16$& $8/15$\\
    \bottomrule
  \end{tabular}
\end{table}

\subsubsection{Modularity}
\index{modules}

Each run directory has a file \file{src/Makefile.local} in which you
choose certain \name{modules}\footnote{%
  We stress once more that we are not talking about F90 modules here,
  although there is some connection, as most of our modules define F90
  modules:
  For example each of the three modules \name{grav_z}, \name{grav_r} and
  \name{nograv} define a Fortran module \name{Gravity}.
}, which tell the code whether or not entropy, magnetic fields,
hydrodynamics, density, forcing, etc.~should be invoked.
For example, the settings for forced turbulent MHD simulations are
\begin{verbatim}
  HYDRO    =   hydro
  DENSITY  =   density
  ENTROPY  = noentropy
  MAGNETIC =   magnetic
  GRAVITY  = nograv
  FORCING  =   forcing
    
  MPICOMM  = nompicomm
  GLOBAL   = noglobal
  IO       =   io_dist
\end{verbatim}
This file will be processed by \cmd{make} and the settings are thus
assignments of \name{make} variables.
Apart from the physics modules (equation of motion: yes, density
[pressure]: yes, entropy equation: no, magnetic fields: yes, gravity: no,
forcing: yes), a few technical modules can also be used or deactivated; in
the example above, these are \name{MPI} (switched off), additional global
variables (none) and input/output (there is currently only one module
available).
Table~\ref{Tab-modules} lists all currently available modules.

\begin{table}
  \small
  \centering
  \caption{%
    Switchable modules as of June 2002.
  }
  \label{Tab-modules}
  \begin{tabular}{lp{0.6\textwidth}}
    \toprule
    hydro.f90      & Hydrodynamics: add variable $\uv$ with equation of
                     motion; \\
    nohydro.f90    & no variable $\uv$: useful for kinematic dynamo runs. \\
    \midrule
    density.f90    & Add variable $\ln\varrho$ with continuity equation \\
    nodensity.f90  & no variable $\ln\varrho$: useful for Burgers' equation. \\
    \midrule
    entropy.f90    & Add variable $s$ with entropy equation (energy
                     equation); \\
    noentropy.f90  & no variable $s$: isothermal hydrodynamics. \\
    \midrule
    magnetic.f90   & Add variable $\Av$ (magnetic vector potential) with
                     induction equation; \\
    nomagnetic.f90 & no variable $\Av$: nonmagnetic hydrodynamics. \\
    \midrule
    pscalar.f90    & Add variable $\ln c$ (concentration) with
                     advection-diffusion equation for transport of a
                     passive scalar; \\
    nopscalar.f90  & no passive scalar, no variable $\ln c$. \\
    \midrule
    \midrule
    forcing.f90    & Add a forcing function to rhs of equation of motion
                    (typically helical forcing) for forced turbulence
                    calculations; \\
    noforcing.f90  & no forcing. \\
    \midrule
    shear.f90      & Shearing-box boundary conditions; \\
    noshear.f90    & no shearing box. \\
    \midrule
    grav_z.f90     & Constant vertical gravity in equation of motion; \\
    grav_r.f90     & radially symmetric gravity; \\
    nograv.f90     & no gravity. \\
    \midrule
    \midrule
    global_rr.f90  & Radius \verb|rr| as an additional global variable; \\
    global_pot.f90 & radially symmetric gravity potential as additional
                     global variables; \\
    noglobal.f90   & no additional global variables. \\
    \midrule
    fft.f          & Singleton (1968) FFT routine: needed for magnetic
                     potential-field boundary condition; \\
    nofft.f90      & no FFT: no need to bother about compiler warnings if
                     you don't need this boundary condition. \\
    \midrule
    io_dist.f90    & Distributed input/output: each processor writes to
                     its own directory; currently there are no
                     alternatives. \\
    \midrule
    mpicomm.f90    & Use \name{MPI} for communication on multiprocessor
                     machines; \\
    nompicomm.f90  & no parallelization: convenient for testing and
                     smaller production runs on desktop or notebook
                     computers. \\
    \midrule
    debug_c.c      & Use I/O routines that allow to write auxiliary
                     variables to a file (nontrivial in a pencil code);
                     requires C compiler to be set up correctly and maybe
                     requires appropriate compiler flags
                     (\code{-DFUNDERSCORE}) for correctly interfacing C
                     with Fortran (and may still not work in some cases); \\
    nodebug.f90    & don't use these debugging routines, avoiding any
                     C-Fortran interoperability problems. \\
    \bottomrule
  \end{tabular}
\end{table}
% ---------------------------------------------------------------------- %


Note that most of these \name{make} variables \emph{must} be set, but they
will normally obtain reasonable default values in \file{Makefile}.
It is by using this switching mechanism through \cmd{make} that we achieve
high flexibility without resorting to excessive amounts of cryptic
preprocessor directives.
 
Many possible combinations of modules have already been tested
and examples are part of the distribution, but you may be interested in a
combination which was never tried before and which may not yet work, since the
modules are not fully orthogonal.
In all such cases, we depend on your feedback for fixing the problems
and documenting the changes for others.


% ---------------------------------------------------------------------- %

\subsection{Files}

\subsubsection{start.in, run.in}

\subsubsection{param.nml, param2.nml; param[2].pro}


% ---------------------------------------------------------------------- %

\subsection{I/O diagnostics}


% ====================================================================== %

\section{Using the Code}
\label{Input-params}


% ---------------------------------------------------------------------- %

\subsection{Localization (adapt-mkfile)}
\label{adapt-mkfile}

By default, one \file{makefile} will only work on a given class of
computers with identical (or at least similar) compilers.
Our aim when building the pencil code was however to allow running the
code on different machines without any need to modify files.
This, together with \name{CVS} allows you for example to very quickly
compare results for identical runs on different machines.

Our mechanism for picking the right set of compiler flags is based on the
\name{Perl} script \file{adapt-mkfile} in \file{\$PENCIL_HOME/bin}, which
processes the file \file{Makefile} to a (localized) \file{makefile}.
When both \file{Makefile} and \file{makefile} are present, \cmd{make} will
use the latter.
You can view the full documentation for \cmd{adapt-mkfile} with the
command
\begin{alltt}
  \prompt{unix > } perldoc adapt-mkfile
\end{alltt}
provided \file{\$PENCIL_HOME/bin} is in your path.

To give you an idea of how to add you own machines, let us assume you have
several Linux boxes running a compiler \cmd{f95} that needs the options
\option{-O4 -u}, while one of them, \name{Janus}, runs a compiler \cmd{f90}
which needs the flags \option{-O3} and requires the additional
options \option{-lmpi -llam} for \name{MPI}.

The \file{Makefile} you need will have the following section:
\begin{alltt}
  ### Begin machine dependent
  
  ## IRIX64:
  {\sl{}[\ldots]   (leave as it is in the original Makefile)}
  ## OSF1:
  {\sl{}[\ldots]   (leave as it is in the original Makefile)}
  
  ## Linux:
  {\sl{}[\ldots]   (leave everything from original Makefile and add:)}
  #FC=f95
  #FFLAGS=-O3 -u
  #FC=f90             #(Janus)
  #FFLAGS=-O3 -u      #(Janus)
  #LDMPI=-lmpi -llam  #(Janus)
  
  ## SunOS:
  {\sl{}[\ldots]   (leave as it is in the original Makefile)}
  ## UNICOS/mk:
  {\sl{}[\ldots]   (leave as it is in the original Makefile)}
  ## HI-UX/MPP:
  {\sl{}[\ldots]   (leave as it is in the original Makefile)}
  ## AIX:
  {\sl{}[\ldots]   (leave as it is in the original Makefile)}
  
  ### End machine dependent
\end{alltt}


% ---------------------------------------------------------------------- %

\subsection{I/O diagnostics}
\label{diagnostic-IO}

Every \var{it1} time steps (\var{it1} is a runtime parameter, see
Sect.~\ref{Run-params}), the code writes monitoring output to \name{stdout}
and, parallel to this, to the file \file{tmp/n.dat}.
The variables that appear in this listing and the output format are
defined in the file \file{print.in} and can be changed without touching
the code (even while the code is running).
A simple example of \file{print.in} may look like this:
\begin{verbatim}
  t(f10.3)
  urms(1pe13.4)
  rhom(0pf10.5)
  oum
\end{verbatim}
which means that the output table will contain time \var{t} in the first
column formatted as \verb|(f10.3)|, followed by the mean squared velocity,
\var{urms} (i.e.~$\left<\uv^2\right>$) in the second column with format
\verb|(1pe13.4)|, the average density \var{rhom} ($\left<\varrho\right>$,
which allows to monitor mass conservation) formatted \verb|(f10.5)| and
the kinetic helicity \var{oum}
(that is $\left<\vec{\omega}\cdot\uv\right>$) in the last column with the
default format \verb|(1pe10.2)|.\footnote{
  Note that immediately after a format that uses the modifier \code{1p},
  on should switch back to \code{0p}, since otherwise the following numbers
  printed with \code{f} formats will be one order of magnitude off.
  This is the sad heritage of some more obscure Fortran I/O features.
}
The corresponding diagnostic output will look like
\begin{verbatim}
 ----t---------urms--------rhom------oum----
     0.000   4.9643E-03  14.42457 -8.62E-06
     0.032   3.9423E-03  14.42446 -5.25E-06
     0.063   6.8399E-03  14.42449 -3.50E-06
     0.095   1.1437E-02  14.42455 -2.58E-06
     0.126   1.6980E-02  14.42457 -1.93E-06
\end{verbatim}

In the file \file{zaver.in}, $z$-dependent (horizontal) averages are listed.
They are written to the file \file{tmp/zaverages.dat}. At the moment we
can also output in \file{print.in} the associated mean square value
of the horizontal field, but this requires that in \file{zaver.in} the
quantities \code{bxmz} and \code{bymz} are set.

% ---------------------------------------------------------------------- %

\subsection{Helper scripts}
\index{Scripts}

\begin{description}
  \item[adapt-mkfile]
  \item[lnsrc]
  \item[new]
  \item[nl2idl]
  \item[timestr]
  \item[x]
  \item[tsnap]
\end{description}

\vspace{5cm}

% ---------------------------------------------------------------------- %

\subsection{RELOAD and STOP files}

The code periodically (every \var{it} time steps) checks 
for the existence of two files, \file{RELOAD}
and \file{STOP}, which can be used to trigger certain behavior.

\paragraph{Reloading run parameters}
In the directory where you started the code, create the file
\file{RELOAD} with
\begin{alltt}
  \prompt{unix> } touch RELOAD \
\end{alltt}
to force the code to re-read the runtime parameters from \file{run.in}.
This will happen the next time the code is writing monitoring output (the
frequency of this happening is controlled by the input parameter \var{it},
see Sect.~\ref{start-params}).

\paragraph{Stopping the code}
In the directory where you started the code, create the file
\file{STOP} with
\begin{alltt}
  \prompt{unix> } touch STOP \
\end{alltt}
to stop the code in a controlled manner (it will write the latest
snapshot).
Again, the action will happen the next time the code is writing monitoring
output.


% ---------------------------------------------------------------------- %


\subsection{Start parameters}
\label{start-params}

All input parameters in \file{start.in} (and \file{run.in}) occur in
namelists.
This allows arbitrary order of the parameters (\emph{within} the given
namelist; the namelists need to appear in the correct order), as well as
inserted Fortran comments and whitespace for readability.
One namelist (\name{init_pars}) contains general parameters for
initialization and is always read in.
All other namelists are specific to individual modules and will only
be read if the corresponding module is used.

The syntax of a namelist (in an input file like \file{start.in}) is
\begin{verbatim}
  &init_pars
    ip=5, Lxyz=2,4,2
  /
\end{verbatim}
--- in this example, we read just two variables (all other variables in
the namelist retain their previous value): \var{ip}, which is set to $5$,
and \var{Lxyz}, which is a vector of length three and is set to $(2,4,5)$.

While all parameters from the namelists can be set, in most cases
reasonable default values are preset.
Thus, the typical file \file{start.in} will only contain a minimum set of
variables or (if you are \emph{very} minimalistic) none at all.
If you want to run a particular problem, it is best to start by
modifying a particular example which is closest to your application.

The following table lists all (at the time of writing, July 2002)
namelists with their corresponding start parameters (file \file{start.in})
and their default values (in square brackets).
Any variable referred to as a \dfn{flag} can be set to any nonzero value
to switch the corresponding feature on.
Not all parameters are used for a given scenario.
This list is likely to not be up to date; also, in many cases it can only
give an idea of the corresponding initial state; to get more insight and
the latest information, you should have a look at the code.

The value $\varepsilon$ corresponds to 5 times the smallest number larger
than zero.
For single precision, this is typically about
$\varepsilon \approx 5\times1.2{\times}10^{-7} = 6{\times}10^{-7}$; for
double precision, $\varepsilon\approx10^{-15}$.

% ---------------------------------------------------------------------- %
\begin{longtable}{lp{0.6\textwidth}}
%\begin{tabular}{lp{0.6\textwidth}}
\toprule
  \multicolumn{1}{c}{\emph{Variable [default value]}}
               & \multicolumn{1}{c}{\emph{Meaning}} \\
\midrule
  \multicolumn{2}{c}{Namelist \name{init_pars}}\\
\midrule
  \var{cvsid} [\code{''}]
               & the \name{CVS} identification string, which allows you to
                 keep track of the version of \file{start.in}.\\
  \var{ip} [$14$]
               & (anti-)verbosity level: \code{ip=1} produces lots of
                 diagnostic output, \code{ip=14} virtually none. \\
  \var{xyz0} [$(-\pi,-\pi,-\pi)$],\\
  \var{Lxyz} [$(2\pi,2\pi,2\pi)$],\\
  \var{lperi} [(\code{T},\code{T},\code{T})]
               & determine the geometry of the box. All three are vectors
                 of the form ($x$-comp., $y$-comp., $z$-comp.); \var{xyz0}
                 describes the left (lower) corner of the box, \var{Lxyz}
                 the box size.
                 \var{lperi} specifies whether a direction is considered
                 periodic (in which case the last point is omitted) or not.
                 In all cases, three ghost zones will be added. \\
  \var{lwrite_ic} [\code{F}]
               & If set \code{T}, the initial data are written into the
                 file \file{VAR0}. This is generally useful, but doing this
                 all the time uses up plenty of disk space.\\
  \var{lnowrite} [\code{F}]
               & If set \code{T}, all initialization files are written,
                 except file{var.dat}. This option allows you to use old
                 file{var.dat} files, but updates all other initialization
                 files. This could be useful after having changed the code.\\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{hydro_init_pars}} \\
\midrule
  \var{inituu} [\code{'zero'}]
               & initialization of velocity. Currently valid choices are
                 \begin{description}
                 \item[\code{`zero'}] ($\uv=0$ ),
                 \item[\code{`random-normal'}] (random,
                   normally-distributed $u_x$),
                 \item[\code{`sound=wave'}] (sound wave in $x$ direction),
                 \item[\code{`shock-tube'}] (polytropic standing shock).
                 \end{description}
                 \\
  \var{ampluu} [$0.$]
               & amplitude for some types of initial velocities. \\
  \var{widthuu} [$0.1$]
               & width for some types of initial velocities. \\
  \var{urand} [$0.$]
               & additional random perturbation of $\uv$. If
                 \verb|urand>0|, the perturbation is additive,
                 $u_i \mapsto u_i + u_{\rm rand}{\cal U}_{[0.5,0.5]}$;
                 if \verb|urand<0|, it is multiplicative,
                 $u_i \mapsto u_i \times u_{\rm rand}{\cal U}_{[0.5,0.5]}$;
                 in both cases, ${\cal U}_{[0.5,0.5]}$ is a uniformly
                 distributed random variable on the interval $[-0.5,0.5]$.\\
  \var{uu_left} [$0.$], \\
  \var{uu_right} [$0.$]
               & needed for \code{inituu='shock-tube'}.\\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{density_init_pars}} \\
\midrule
  \var{initlnrho} [\code{'zero'}]
               & initialization of density. Currently valid choices are
                 \begin{description}
                 \item[\code{`zero'}] ($\ln\varrho=0$),
                 \item[\code{`isothermal'}] (isothermal stratification),
                 \item[\code{`polytropic\_simple'}] (polytropic stratification),
                 \item[\code{`hydrostatic-z-2'}] (hydrostatic vertical
                   stratification for isentropic atmosphere),
                 \item[\code{`rho-jump'}] (density jump of width
                   \var{widthlnrho}),
                 \item[\code{`piecew-poly'}] (piecewise polytropic vertical
                   stratification for solar convection),
                 \item[\code{`polytropic'}] (polytropic vertical
                   stratification),
                 \item[\code{`sound-wave'}] (sound wave),
                 \item[\code{`shock-tube'}] (polytropic standing shock).
                 \end{description}
                 \\
  \var{gamma} [$5./3$]
               & adiabatic index $\gamma=c_p/c_v$. \\
  \var{cs0} [$1.$], \\
  \var{rho0} [$1.$]
               & \label{cs0-rho0-init}%
                 reference values of sound speed and density,
                 i.\,e.~values at height \var{zref}. \\
  \var{ampllnrho} [$0.$], \\
  \var{widthlnrho} [$0.1$]
               & amplitude and width for some types of initial densities. \\
  \var{rho_left} [$1.$], \\
  \var{rho_right} [$1.$]
               & needed for \code{initlnrho='shock-tube'}. \\
  \var{cs2bot} [$1.$], \\
  \var{cs2top} [$1.$]
               & sound speed at bottom and top. Needed for some types of
                 stratification. \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{grav_init_pars}} \\
\midrule
  \var{zref} [$0.$]
               & \label{zref-init}%
                 reference height where in the initial stratification
                 $c_{\rm s}^2=c_{\rm s0}^2$ and $\ln\varrho=\ln\varrho_0$.\\
  \var{gravz} [$-1.$]
               & vertical gravity component $g_z$.\\
  \var{grav_profile} \\{}
    [\code{'const'}]
               & constant gravity $g_z = \texttt{gravz}$
                 (\code{grav_profile='const'}) gravity
                 or linear profile $g_z = \texttt{gravz}\cdot z$
                 (\code{grav_profile='linear'}, for accretion discs and
                 similar). \\
  \var{z1} [$0.$], \\
  \var{z2} [$1.$]
               & specific to the solar convection case
                 \code{initlnrho='piecew-poly'}.
                 The stable layer is $z_0 < z < z_1$, the unstable layer
                 $z_1 < z < z_2$, and the top (isothermal) layer is
                 $z_2 < z < z_{\rm top}$. \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{entropy_init_pars}} \\
\midrule
  \var{initss} [\code{'nothing'}]
               & initialization of entropy. Currently valid choices are
                 \begin{description}
                 \item[\code{`nothing'}] (leaves the initialization done
                   in the density module unchanged),
                 \item[\code{`zero'}] (put $s=0$ explicitly; this may
                   overwrite the initialization done in the density module),
                 \item[\code{`isothermal'}] (isothermal stratification,
                   $T=\const$),
                 \item[\code{`isobaric'}] (isobaric, $p=\const$),
                 \item[\code{`isentropic'}] (isentropic with superimposed
                   hot [or cool] bubble),
                 \item[\code{`linprof'}] (linear entropy profile in $z$),
                 \item[\code{`piecew-poly'}] (piecewise polytropic
                   stratification for convection),
                 \item[\code{`polytropic'}] (polytropic stratification,
                   polytropic exponent is \var{mpoly0}).
                 \end{description}
                 \\
  \var{pertss} [\code{'zero'}]
               & additional perturbation to entropy. Currently valid
                 choices are
                 \begin{description}
                 \item[\code{'zero'}] (no perturbation)
                 \item[\code{'hexagonal'}] (hexagonal perturbation for
                   convection).
                 \end{description}
                 \\
  \var{ampl_ss} [$0.$], \\
  \var{widthss} [$2\varepsilon$]
               & amplitude and width for some types of initial entropy. \\
  \var{grads0} [$0.$]
               & initial entropy gradient for \code{initss=linprof}. \\
  \var{radius_ss} [$0.1$]
               & radius of bubble for \code{initss=isentropic}. \\
  \var{mpoly0} [$1.5$], \\
  \var{mpoly1} [$1.5$], \\
  \var{mpoly2} [$1.5$]
               & \label{mpoly012-init}%
                 specific to the solar convection case
                 \code{initss=piecew-poly}:
                 polytropic indices of unstable (\var{mpoly0}), stable
                 (\var{mpoly1}) and top layer (\var{mpoly2}).
                 If the flag \var{isothtop} is set, the
                 top layer is initialized to be isothermal, otherwise
                 thermal (plus hydrostatic) equilibrium is assumed for all
                 three layers, which results in a piecewise polytropic
                 stratification. \\
  \var{isothtop} [$0$]
               & flag for isothermal top layer for \code{initss=piecew-poly}. \\
  \var{khor_ss} [$1.$]
               & horizontal wave number for \code{initss=hexagonal} \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{magnetic_init_pars}} \\
\midrule
  \var{initaa} [\code{'zero'}]
               & initialization of magnetic field (vector potential).
                 Currently valid choices are
                 \begin{description}
                 \item[\code{`zero'}] (zero field),
                 \item[\code{`gaussian-noise'}] (white noise),
                 \item[\code{`Beltrami-x'}] ($x$-dependent Beltrami wave),
                 \item[\code{`Beltrami-y'}] ($y$-dependent Beltrami wave),
                 \item[\code{`Beltrami-z'}] ($z$-dependent Beltrami wave),
                 \item[\code{`hor-fluxtube'}] (horizontal flux tube),
                 \item[\code{`hor-fluxlayer'}] (horizontal flux layer),
                 \item[\code{`uniform-Bx'}] (uniform field in $x$ direction),
                 \item[\code{`Bz(x)'}] ($B_z\propto\cos(k x)$),
                 \item[\code{`fluxrings'}] (two interlocked magnetic fluxrings;
                   see Sect.~\ref{fluxrings}),
                 \item[\code{`crazy'}] (for testing purposes),
                 \item[\code{`Alfven-circ-x'}] (circularly polarized
                   Alfvn wave).
                 \end{description}
                 \\
  \var{initaa2} [\code{'zero'}]
               & additional perturbation of magnetic field.
                 Currently valid choices are
                 \begin{description}
                 \item[\code{`zero'}] (zero perturbation),
                 \item[\code{`Beltrami-x'}] ($x$-dependent Beltrami wave),
                 \item[\code{`Beltrami-y'}] ($y$-dependent Beltrami wave),
                 \item[\code{`Beltrami-z'}] ($z$-dependent Beltrami wave).
                 \end{description}
                 \\
  \var{amplaa} [$0.$]
               & amplitude for some types of initial magnetic fields. \\
  \var{amplaa2} [$0.$]
               & amplitude for some types of magnetic field perturbation. \\
  \var{fring\{1,2\}} [$0.$], \\
  \var{Iring\{1,2\}} [$0.$], \\
  \var{Rring\{1,2\}} [$1.$], \\
  \var{wr\{1,2\}} [$0.3$]
               & flux, current, outer and inner radius of flux ring 1/2;
                 see Sect.~\ref{fluxrings}. \\
  \var{radius} [$0.1$]
               & used by some initial fields. \\
  \var{epsilonaa} [$10^{-2}$]
               & used by some initial fields. \\
  \var{widthaa} [$0.5$]
               & used by some initial fields. \\
  \var{z0aa} [$0.$]
               & used by some initial fields. \\
  \var{kx_aa} [$1.$], \\
  \var{ky_aa} [$1.$], \\
  \var{kz_aa} [$1.$]
               & wavenumbers used by some initial fields. \\
  \var{lpress_equil} [F]
               & flag for pressure equilibrium (can be used in connection
                 with all initial fields) \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{pscalar_init_pars}} \\
\midrule
  \var{initlncc} [\code{'zero'}]
               & initialization of passive scalar
                 (concentration per unit mass, $c$).
                 Currently valid choices (for $\ln c$) are
                 \begin{description}
                 \item[\code{`zero'}] ($\ln c=0.$),
                 \item[\code{`gaussian-noise'}] (white noise),
                 \item[\code{`wave-x'}] (wave in $x$ direction),
                 \item[\code{`wave-y'}] (wave in $y$ direction),
                 \item[\code{`wave-z'}] (wave in $z$ direction).
                 \end{description}
                 \\
  \var{initlncc2} [\code{'zero'}]
               & additional perturbation of passive scalar concentration $c$.
                 Currently valid choices are
                 \begin{description}
                 \item[\code{`zero'}] ($\delta\ln c=0.$),
                 \item[\code{`wave-x'}] (add $x$-directed wave to $\ln c$).
                 \end{description}
                 \\
\var{ampllncc} [$0.1$]
               & amplitude for some types of initial concentration. \\
  \var{ampllncc2} [$0.$]
               & amplitude for some types of concentration perturbation. \\
  \var{kx_lncc} [$1.$], \\
  \var{ky_lncc} [$1.$], \\
  \var{kz_lncc} [$1.$]
               & Wave numbers for some types of initial concentration. \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{shear_init_pars}} \\
\midrule
  \var{qshear} [$0.$]
               & \label{qshear-init}%
                 Degree of shear for shearing-box simulations (the
                 shearing-periodic boundaries are the $x$-boundaries and
                 are sheared in the $y$-direction). The shear velocity
                 is ${\bf U}=-q\Omega x\,{\hat{\bf y}}$. \\
\bottomrule
%\end{tabular}
\end{longtable}
% ---------------------------------------------------------------------- %


% ---------------------------------------------------------------------- %

\subsection{Run parameters}
\label{Run-params}


The following table lists all (at the time of writing, July 2002)
namelists with their corresponding run parameters (file \file{run.in}) and
their default values (in square brackets).
Default values marked as [start] are taken from \file{start.in}.
Any variable referred to as a \dfn{flag} can be set to any nonzero value
to switch the corresponding feature on.
Not all parameters are used for a given scenario.
This list is likely to not be up to date; also, in many cases it can only
give an idea of the corresponding initial state; to get more insight and
the latest information, you should have a look at the code.


% ---------------------------------------------------------------------- %
\begin{longtable}{lp{0.6\textwidth}}
%\begin{tabular}{lp{0.6\textwidth}}
\toprule
  \multicolumn{1}{c}{\emph{Variable [default value]}}
               & \multicolumn{1}{c}{\emph{Meaning}} \\
\midrule
  \multicolumn{2}{c}{Namelist \name{init_pars}}\\
\midrule
  \var{cvsid} [\code{''}]
               & the \name{CVS} identification string, which allows you to
                 keep track of the version of \file{run.in}. \\
  \var{ip} [$14$]
               & (anti-)verbosity level: \code{ip=1} produces lots of
                 diagnostic output, \code{ip=14} virtually none. \\
  \var{nt} [$0$]
               & number of time steps to run (at most). \\
  \var{it1} [$10$]
               & write diagnostic output every \var{it} time steps 
                 (see Sect.~\ref{diagnostic-IO}). \\
  \var{cdt} [$0.4$]
               & Courant coefficient for advective time step; see
                 \S\ref{time-step}. \\
  \var{cdtv} [$0.08$]
               & Courant coefficient for diffusive time step; see
                 \S\ref{time-step}. \\
  \var{dt} [$0.$]
               & \label{dt-run}%
                 time step; if $\ne 0.$, this overwrites
                 the Courant time step. See \S\ref{time-step} for a
                 discussion of the latter. \\
  \var{dtmin} [$10^{-6}$]
               & abort if time step $\delta t < \delta t_{\rm min}$. \\
  \var{tmax} [$10^{33}$]
               & don't run time steps beyond this time. Useful if you want
                 to run for a given amount of time, but don't know the
                 necessary number of time steps.\\
  \var{isave} [$100$]
               & update current snapshot \file{var.dat} every \var{isave}
                 time steps. \\
  \var{itorder} [$3$]
               & order of time step (1 for Euler; 2 for 3nd-order, 3 for
                 3rd-order Runge--Kutta). \\
  \var{dsnap} [$100.$]
               & save permanent snapshot every \var{dsnap} time units to
                 files \file{VAR$n$}, where $n$ counts from $n=1$ upwards.
                 (This information is stored in the file \file{tmp/tsnap.dat};
                 see the module \var{wsnaps.f90}, which in turn uses the
                 subroutines \var{out1} and \var{out2}.) \\
  \var{dvid} [$100.$]
               & write two-dimensional sections for generation of videos
                 every \var{dvid} time units (not timesteps; see the
                 subroutines \var{out1} and \var{out2} in the code). \\
  \var{iwig} [$0$]
               & if $\ne 0$, apply a Nyquist filter (a filter eliminating
                 any signal at the Nyquist frequency, but affecting large
                 scales as little as possible) every \var{iwig} time steps to
                 logarithmic density (sometimes necessary with convection
                 simulations). \\
  \var{ialive} [$0$]
               & if $\ne 0$, each processor writes the current time step
                 to \file{alive.info} every \var{ialive} time steps. 
                 (This can be used to find out which node has crashed
                 if there is a problem and the run is hanging.)\\
  \var{bcx} [(\code{'p'}, \code{'p'}, \ldots)], \\
  \var{bcy} [(\code{'p'}, \code{'p'}, \ldots)], \\
  \var{bcz} [(\code{'p'}, \code{'p'}, \ldots)]
               & boundary conditions. See Sect.~\ref{boundconds} for a
                 discussion. \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{hydro_run_pars}} \\
\midrule
  \var{nu} [$0.$]
               & kinematical viscosity. \\
  \var{ivisc} [$0$]
               & select form of viscous term; currently valid choices are
                 \begin{description}
                 \item[\code{'simplified'}] -- simplified viscous force
                   $\Fv_{\rm visc}=\nu\Laplace\uv$
                 \item[\code{'rho_nu-const'}] -- viscous force for
                   $\mu\equiv\varrho\nu=\const$,
                   $\Fv_{\rm visc}=\mu/\varrho(\Laplace\uv+1/3\grad\Div\uv)$
                 \item[\code{'nu-const'}] -- viscous force for $\nu=\const$,
                   $\Fv_{\rm visc}=\mu/\varrho(\Laplace\uv+1/3\grad\Div\uv
                    + 2\mathsf{S}\cdot\grad\ln\varrho)$
                 \end{description}
                 \\
  \var{Omega} [$0.$]
               & magnitude of angular velocity for Coriolis force (note:
                 no centrifugal force is implemented). \\
  \var{theta} [$0.$]
               & direction of angular velocity ($\vartheta=0$ for
                 $z$-direction, $\vartheta=\pi/2$ for $x$-direction. \\
  \var{ttransient} [$0.$]
               & initial time span for which to do something special
                 (transient).
                 Currently just used to smoothly switch on heating
                 [Should be in \name{run_pars}, rather than here]. \\
  \var{dampu} [$0.$], \\
  \var{tdamp} [$0.$]
               & damp motions during the initial time interval
                 $0<t<t_{\rm damp}$ with a damping term $-\var{dampu}(\uv)$.
                 Useful for situations where initial conditions are not near
                 equilibrium. \\
  \var{dampuext} [$0.$], \\
  \var{rdamp} [$1.2$], \\
  \var{wdamp} [$0.2$]
               & permanently damp motions in $|\xv|>r_{\rm damp}$ with
                 damping term $-\var{damp}_u \,\uv\,\chi(r{-}r_{\rm damp})$,
                 where $\chi(\cdot)$ is a smooth profile of width
                 \var{wdamp}. \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{density_run_pars}} \\
\midrule
  \var{cs0} [start], \\
  \var{rho0} [start], \\
  \var{gamma} [start]
               & see start parameters, p.~\pageref{cs0-rho0-init} \\
  \var{cdiffrho} [$0.$]
               & Coefficient for mass diffusion (diffusion term will be
                 $c_{\rm diffrho}\,\delta x\, {\cs}_0$ . \\
  \var{cs2bot} [start], \\
  \var{cs2top} [start]
               & squared sound speed at bottom and top for boundary
                 condition \option{c2}. \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{entropy_run_pars}} \\
\midrule
  \var{hcond0} [$0.$], \\
  \var{hcond1} [start], \\
  \var{hcond2} [start]
               & specific to the solar convection case
                 \code{initss=piecew-poly}:
                 heat conductivities $\lambda$ in the individual layers.
                 \var{hcond0} is the value $\lambda_{\rm unst}$ in the
                 unstable layer, \var{hcond1} is the \emph{ratio}
                 $\lambda_{\rm stab}/\lambda_{\rm unst}$ for the stable
                 layer, and \var{hcond2} is the \emph{ratio} 
                 $\lambda_{\rm top}/\lambda_{\rm unst}$ for the top layer.
                 The function $\lambda(z)$ is not discontinuous, as the
                 transition between the different values is smoothed over
                 the width \var{widthss}.
                 if \var{hcond1} or \var{hcond2} are not set, they are
                 calculated according to the polytropic indices of the
                 initial profile, $\lambda\propto m{+}1$. \\
  \var{widthss} [start]
               & width of transition region between layers.
                 See start parameters, p.~\pageref{mpoly012-init}. \\
  \var{isothtop} [start]
               & flag for isothermal top layer for solar convection case.
                 See start parameters, p.~\pageref{mpoly012-init}. \\
  \var{cheat} [$0.$], \\
  \var{wheat} [$0.1$]
               & strength and width of heating region. \\
  \var{cool} [$0.$], \\
  \var{wcool} [$0.1$]
               & strength and width of cooling region. \\
  \var{Fheat} [start]
               & heat flux for boundary condition \option{c1}.
                 For polytropic atmospheres calculated by \cmd{start.x}. \\
  \var{chi_t} [$0.$]
               & entropy diffusion coefficient for diffusive term
                 $\partial s/\partial t = \ldots + \chi_{\rm t}\Laplace s$
                 in the entropy equation, that can represent some kind of
                 turbulent (sub-grid) mixing.
                 It is probably a bad idea to combine this with heat
                 conduction $\var{hcond0} \ne 0$. \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{magnetic_run_pars}} \\
\midrule
  \var{B_ext} [$(0.,0.,0.)$]
               & uniform background magnetic field (for fully periodic
                 boundary conditions, uniform fields need to be explicitly
                 added, since otherwise the vector potential $\Av$ has a
                 linear $\xv$-dependence which is incompatible with
                 periodicity). \\
  \var{eta} [$0.$]
               & magnetic diffusivity $\eta=1/(\mu_0\sigma)$, where
                 $\sigma$ is the electric conductivity. \\
  \var{height_eta} [$0.$], \\
  \var{eta_out} [$0.$]
               & used to add extra diffusivity in a halo region. \\
  \var{kinflow} [\code{''}]
               & set type of flow fixed with \option{nohydro}. Currently
                 the only recognized value is \code{'ABC'} for an $ABC$
                 flow; all other values lead to $\uv=\zerovect$. \\
  \var{kx} [$1.$], \\
  \var{ky} [$1.$], \\
  \var{kz} [$1.$]
               & wave numbers for $ABC$ flow. \\
  \var{ABC_A} [$1.$], \\
  \var{ABC_B} [$1.$], \\
  \var{ABC_C} [$1.$]
               & amplitudes $A$, $B$ and $C$ for $ABC$ flow. \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{pscalar_run_pars}} \\
\midrule
  \var{pscalar_diff} [$0.$]
               & diffusion for passive scalar concentration $c$. \\
  \var{tensor_pscalar_diff} [$0.$]
               & coefficient for non-isotropic diffusion of passive scalar. \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{forcing_run_pars}} \\
\midrule
  \var{iforce} [$2$]
               & select form of forcing in the equation of motion;
                 currently valid choices are
                 \begin{description}
                 \item[\code{'zero'}] (no forcing),
                 \item[\code{'irrotational'}] (irrotational forcing),
                 \item[\code{'helical'}] (helical forcing),
                 \item[\code{'fountain'}] (forcing of ``fountain flow'';
                   cf.~MNRAS 276, 651 for similar reference),
                 \item[\code{'horizontal-shear'}] (forcing localized
                   horizontal sinusoidal shear).
                 \end{description}
                 \\
  \var{iforce2} [$0$]
               & select form of additional forcing in the equation of
                 motion; valid choices are as for \var{iforce}. \\
  \var{force} [$0.$]
               & amplitude of forcing. \\
  \var{relhel} [$1.$]
               & helicity of forcing ($\pm1 \rightarrow$ maximum helicity
                 of either sign). \\
  \var{height_ff} [$0.$]
               & multiply forcing by $z$-dependent profile of width
               \var{height_ff} (if $\ne 0$) . \\
  \var{r_ff} [$0.$]
               & if $\ne 0$, multiply forcing by spherical cutoff profile
                 (of radius \var{r_ff}) and flip signs of helicity at
                 equatorial plane. \\
  \var{width_ff} [$0.5$]
               & width of vertical and radial profiles for modifying
                 forcing. \\
  \var{kfountain} [$5$]
               & horizontal wavenumber of the fountain flow. \\
  \var{fountain} [$1.$]
               & amplitude of the fountain flow. \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{grav_run_pars}} \\
\midrule
  \var{zref} [start], \\
  \var{gravz} [start], \\
  \var{grav_profile} [start]
               & see p.~\pageref{zref-init}. \\
%
\midrule
  \multicolumn{2}{c}{Namelist \name{shear_run_pars}} \\
\midrule
  \var{qshear} [start]
               & See p.~\pageref{qshear-init}. \\
\bottomrule
\end{longtable}
% ---------------------------------------------------------------------- %


\subsection{The time step}
\label{time-step}

The time step is normally specified as Courant time step through the
coefficients \var{cdt} ($c_{\delta t}$) and \var{cdtv} ($c_{\delta t_v}$).
The resulting Courant step is given by
\begin{equation}
  \delta t
  = \min\left( c_{\delta t}\frac{\delta x_{\rm min}}
                    {U_{\rm max}} ,
               c_{\delta t,v}
               \frac{\delta x_{\rm min}^2}
                    {D_{\rm max}}
        \right) \; ,
\end{equation}
where
\begin{equation}
  \delta x_{\rm min} \equiv \min(\delta x, \delta y, \delta z) \; ;
\end{equation}
\begin{equation}
  U_{\rm max} \equiv \max\left(|\uv|
                      + \sqrt{\cs^2{+}\vA^2}\right) \; ,
\end{equation}
$\cs$ and $\vA$ denoting sound speed and Alfv\'en speed, respectively;
and $D_{\rm max} = \max(\nu,\gamma\chi,\eta)$, where
$\nu$ denotes kinematic viscosity,
$\chi = \lambda/(c_p\varrho)$ thermal
diffusivity and $\eta$ the magnetic diffusivity.

To fix the time step $\delta t$ to a value independent of velocities and
diffusivities, use the run parameter \var{dt} (see p.~\pageref{dt-run}).

% ---------------------------------------------------------------------- %

\subsection{Boundary conditions}
\label{boundconds}

Boundary conditions are implemented through three layers of
\name{ghost points} on either boundary, which is a quite natural choice
for an MPI code that uses ghost zones for representing values located on
the neighboring processors anyway.
The desired type of boundary condition is set through the parameters
\var{bc\{x,y,z\}} in \file{run.in}; the nomenclature used is as follows.
Set \var{bc\{x,y,z\}} to a sequence of letters like
\begin{alltt}
  bcx = 'p','p','p', 'p',  'p'
\end{alltt}
for periodic boundaries, or
\begin{alltt}
  bcz = 's','s','a','a2','c1:c2'
\end{alltt}
for non-periodic ones.
Each element corresponds to one of the
variables, which are
$u_x$, $u_y$, $u_z$, $\ln\varrho$, $s/c_p$, $A_x$, $A_x$, $A_x$, $\ln c$
(minus the unused variables) in this order.
\begin{description}
\item[\option{p}] periodic boundary condition
\item[\option{a}] antisymmetric condition w.\,r.\,t.~the
  boundary, i.\,e.~vanishing value
\item[\option{s}] symmetric condition w.\,r.\,t.~the
  boundary, i.\,e.~vanishing first derivative
\item[\option{a2}] antisymmetry w.\,r.\,t.~the
  arbitrary value on the boundary, i.\,e.~vanishing
  second derivative
\item[\option{c1}] special boundary condition for
  $\ln\varrho$ and $s$: constant heat flux through the
  boundary
\item[\option{c2}] special boundary condition for
  $\ln\varrho$ and $s$: constant temperature at the
  boundary
\item[\option{ce}] special boundary condition for
  $s$: constant temperature at the boundary for
  arbitrarily set $\ln\varrho$
\item[\option{db}] low-order one-sided derivatives (``no
    boundary condition'') for density
\end{description}
The special syntax $a$:$b$ (e.\,g.~`\code{c1:c2}') means: use
boundary condition $a$ at the left/lower boundary, but
$b$ at the right/upper one.

If you build a new run.in file from another one with a different number
if variables (\var{noentropy} from \var{entropy}, for example), you need
to remember to adjust the {\it length} of the \var{bcx} to \var{bcz} arrays.
The advantage of the present approach is that it is very easy to exchange
all boundary conditions by a new set of boundary conditions in a particular
direction. (Make everything periodic, for example, or switch off shearing
sheet boundary conditions and have stress-free instead.

% ---------------------------------------------------------------------- %

\subsection{Output files}

\begin{itemize}
\item \file{tmp/n.dat}, file{output diagnostics, depends on what is put in print.in}
\item \file{tsnap.dat}, \file{tvid.dat}
\item \file{tmp/dim.dat}
\item \file{tmp/param.dat} \file{tmp/param2.dat}
\item \file{tmp/proc\emph{X}/var.dat} --- detailed format
\item \file{tmp/proc\emph{X}/VAR\emph{N}} --- same format as
      \file{tmp/proc\emph{X}/var.dat}
\item \file{tmp/proc\emph{X}/seed.dat} --- seed field for forcing
      procedure: must be the same for all processors, because globally
      coherent waves of given wavenumber are used
\item \file{tmp/density.pro}, \file{tmp/hydro.pro}, \file{tmp/entropy.pro},
      \file{tmp/magnetic.pro} --- can be used as include file in \name{IDL}
      and contains the column in which certain variables appear in the
      diagnostics file (\file{n.dat}). It also contains the positions of
      variables in the \file{VAR} files. These positions depend on whether
      \var{entropy} or \var{noentropy}, etc, are invoked.
\item \file{tmp/param.nml}
\end{itemize}


% ---------------------------------------------------------------------- %

\subsection{Visualization}


\subsubsection{IDL routines}
\label{S-IDLroutines}

The basic command sequence is:
\begin{alltt}
  \prompt{unix> } idl
  \prompt{IDL> }  .run start
  \prompt{IDL> }  .run r
  \prompt{IDL> }  {\sl[specific commands]} \
\end{alltt}
You call \file{start.pro} once to initialize the fields and read in the
startup parameters from the code.
Each time you want to read in a new snapshot, you run \file{r.pro} (or
\file{rall.pro}, see below),
possibly after adjusting the IDL variable \var{file} to a specific snapshot
file; by default, the file \file{var.dat} in the data directory will be
read, which is overwritten with new data in regular intervals.

If the data are scattered over different processors and you want to
reassemble everything into one file, you use
\begin{alltt}
  \prompt{IDL> }  .r rall
\end{alltt}
instead of \cmd{.r run}.
Here, \cmd{.r} is a shorthand for \cmd{.run}.
The procedure \file{rall.pro} reads (and assembles) the data from all
processors and correspondingly requires large amounts of memory for very
large runs.
If you want to look at just one processor, use \file{r.pro} instead.

If you need the magnetic field or the current density, you can calculate
them in IDL by \footnote{
  Keep in mind that \code{jj=curl(bb)} would use iterated first derivatives
  instead of the second derivatives and thus be numerically less accurate,
  particularly at small scales.
}
\begin{alltt}
  \prompt{IDL> }  bb=curl(aa)
  \prompt{IDL> }  jj=curl2(aa)
\end{alltt}

By default one is reading always the latest time corresponding to the file
\file{var.dat}; if you want to read any earlier snapshots, you say (for
example)
\begin{alltt}
  \prompt{IDL> }  file='VAR2'
  \prompt{IDL> }  .r rall
  \prompt{IDL> }  print,t
\end{alltt}
and it will get the data for that snapshot from all processors.

To discuss:
\begin{itemize}
\item availability of IDL (demo version; Pvwave; Ana)?
\item setup (include \file{../idl} and \file{../../idl} (?) in \var{!path})
\item how to get our IDL routines
\end{itemize}


% ---------------------------------------------------------------------- %

\subsection{Running on multi-processor computers}
\label{MPI}

The code is parallelized using \name{MPI} (\dfn{message passing
interface}) for a simple domain decomposition (data-parallelism), which is
a straight-forward and very efficient way of parallelizing
finite-difference codes.
The current version has a few restrictions, which you should keep in mind
when you use the MPI features.

First, only the $y$ and $z$ directions can be distributed over several
processors.
Second, the global number of grid points (but excluding the ghost zones)
in a given direction must be an exact multiple of the number of processors
you use in that direction.
E.\,g.~if you have \code{nprocy=8} processors for the $y$ direction, you
can run a job with \code{nygrid=64} points in that direction, but if you
try to run a problem with \code{nygrid=65} or \code{nygrid=94}, the code
will stop with an inconsistency message.


\subsubsection{How to run a sample problem in parallel}

To run the sample problem in the directory \file{samples/conv-slab} on 16
CPUs, you need to do the following (in that directory):

\begin{enumerate}

\item Edit \file{src/Makefile.local} and replace
  \begin{alltt}
  MPICOMM   = nompicomm \
  \end{alltt}
  by
  \begin{alltt}
  MPICOMM   =   mpicomm \
  \end{alltt}

\item Edit \file{src/cparam.local} and replace
  \begin{alltt}
  integer, parameter :: ncpus=1,nprocz=1,nprocy=ncpus/nprocz,nprocx=1
  integer, parameter :: nxgrid=32,nygrid=nxgrid,nzgrid=nxgrid \
  \end{alltt}
  by
  \begin{alltt}
  integer, parameter :: ncpus=16,nprocz=4,nprocy=ncpus/nprocz,nprocx=1
  integer, parameter :: nxgrid=128,nygrid=nxgrid,nzgrid=nxgrid \
  \end{alltt}
  The first line specifies a $4{\times}4$ layout of the data in the $y$
  and $z$ direction.
  The second line increases the resolution of the run because
%on most architectures you won't gain much by 
%AB: one almost always gains something
  running a problem as small as $32^3$ on 16 CPUs would be wasteful.
  Even $128^3$ may still be quite small in that respect.
  For performance timings, one should try and keep the size of the
  problem per CPU the same, so for example $256^3$ on 16 CPUs should
  be compared with $128^3$ on 2 CPUs.

\item Recompile the code
  \begin{alltt}
  \prompt{unix> } (cd src; make)
  \end{alltt}

\item Run it
  \begin{alltt}
  \prompt{unix> } start.csh
  \prompt{unix> } run.csh
  \end{alltt}

\end{enumerate}

Make sure that all CPUs see the same \file{tmp} directory; otherwise
things will go wrong.

Remember that in order to visualize the full domain with IDL (rather than
just the domain processed and written by one processor), you need to use
\file{rall.pro} instead of \file{r.pro}.


% ====================================================================== %

\section{The Equations}

The equations solved by the pencil code are basically the standard
compressible MHD equations. However, the modular structure allows
some variations of the MHD equations, as well as switching
some of the equations off (nomagnetic, noentropy, etc.).

% ---------------------------------------------------------------------- %

\subsection{Continuity equation}

\begin{equation}
  \frac{D\ln\varrho}{Dt}
  = - \Div\uv \; .
\end{equation}

Here $\varrho$ denotes density, $\uv$ the fluid velocity, $t$ is time and
$D/Dt \equiv \partial/\partial t + \uv\cdot\grad$ is the convective
derivative.

% ---------------------------------------------------------------------- %

\subsection{Equation of motion}
\label{S-Eqn-of-motion}

\begin{equation}
  \frac{D\uv}{Dt}
   =  -\cs^2\grad\biggl(\frac{s}{c_p} + \ln\varrho\biggr)
      - \grad\Phi
      + \frac{\jv\times\Bv}{\varrho}
      + \nu \left( \Laplace\uv + \frac{1}{3}\grad\Div\uv
      + {\mathsf S}\cdot\grad\ln\varrho\right) \; .
\end{equation}
Here, $\cs^2 = \gamma p/\varrho$ is the squared sound speed,
$\gamma=c_p/c_v$ the ratio of specific heats of \emph{adiabatic index},
$\Phi$ is the gravity potential, $\jv$ the electric current density, $\Bv$
the magnetic flux density, $\nu$ is kinematic viscosity, and ${\mathsf S}$ is
the traceless rate-of-strain tensor (\ref{Eq-S-traceless}).

If \code{ivisc='simplified'}, a simplified version, $\nu\Laplace$, of the
viscous term is used, which is not physically consistent (momentum
conservation is violated for compressible media), but in some cases
this option could be useful during an initial relaxation phase;
it does run somewhat faster).

If \code{ivisc='rho_mu-const'}, it is assumed that 
$\mu \equiv \varrho\nu = \const$ everywhere; in that
case the input parameter $\nu$ is used to give the value of
$\mu/\varrho_0$.
In that case, the term involving the
rate-of-strain tensor does not appear in the equation.

If \code{ivisc='nu-const'}, it is assumed that 
$\nu = \const$ everywhere.

For isothermal hydrodynamics, see \S\ref{entropy} below.

% ---------------------------------------------------------------------- %

\subsection{Induction equation}

\begin{equation}
  \frac{\partial\Av}{\partial t}
  = \uv\times\Bv - \eta\mu_0\jv \; .
\end{equation}

Here $\Av$ is the magnetic vector potential\index{vector potential},
$\Bv = \curl\Av$ the magnetic
flux density, $\eta = 1/(\mu_0\sigma)$ is the magnetic diffusivity
($\sigma$ denoting the electrical conductivity), and $\mu_0$ the
magnetic vacuum permeability.


% ---------------------------------------------------------------------- %

\subsection{Entropy equation}
\index{entropy}%
\label{entropy}%

The current thermodynamics module \file{entropy} formulates the thermal
part of the physics in terms of \emph{entropy} $s$, rather than thermal
energy $e$, which you may be more familiar with.
Thus the two fundamental thermodynamical variables are $\ln\varrho$
and $s$.
The reason for this choice of variables is that entropy is the natural
physical variable for (at least) convection processes: the sign of the
entropy gradient determines convective (in)stability, the
\emph{Rayleigh number} is proportional to the entropy gradient
of the associated hystrostatic reference solution, etc.
The equation solved is
\begin{equation}
  \varrho T\frac{Ds}{Dt}
   =  \Heat - \Cool
      + \Div(\lambda\grad T)
      + \eta\mu_0 \jv^2
      + 2\varrho\nu {\mathsf S}^2 \; .
\end{equation}

Here, $T$ is temperature, $c_p$ the specific heat at constant pressure,
$\Heat$ and $\Cool$ are explicit heating and cooling terms,
$\lambda$ is the thermal conductivity, and
\begin{equation} \label{Eq-S-traceless}
  {\mathsf S}_{ik} = \frac{\partial_i u_k + \partial_k u_i}{2}
                 -\frac{1}{3} \delta_{ik}\Div\uv
\end{equation}
is the traceless rate-of-strain tensor.

\bigskip

Note that by setting $\gamma=1$ and initially $s=0$, one obtains an
isothermal equation of state (albeit at some unnecessary expense of
memory).
Similarly, by switching off the evolution terms of entropy, one immediately
gets polytropic behavior (if $s$ was initially constant) or generalized
polytropic behavior
(where $s$ is not uniform, but $\partial s/\partial t = 0$).

A better way to achieve isothermality is to use the \name{noentropy}
module.

% ---------------------------------------------------------------------- %

\subsection{Transport equation for a passive scalar}

\begin{equation}
  \frac{D\ln c}{Dt}
  = - {\cal D} \left[ \Laplace\ln c + \grad\ln(\varrho c)\cdot\grad\ln c
               \right] \; .
\end{equation}

Here $c$ denotes the concentration (per unit mass) of the passive scalar and
${\cal D}$ its diffusion constant.
Using $\ln c$ instead of $c$ has the advantage to enforce $c>0$ for all
times.


% ====================================================================== %

%\section{Tuning the code for optimal performance}
%AB: what is described below is really a fake; not tuning.
\section{Performance issues}

\subsection{Using a simplified viscosity operator}

For weakly compressible flows (Mach numbers less than 10\%),
there is little difference between the
simplified viscous operator (\code{ivisc='simplified'}; see
\S\ref{S-Eqn-of-motion}) and the full operator
(\code{ivisc='nu-const'}), while the latter is numerically
%considerably
%AB: not in connection with full MHD and other expensive things.
more expensive.

The equation of motion with the simplified
viscous operator does not conserve linear or angular momentum.
It depends on your application whether this is a crucial shortcoming or
totally irrelevant.
In practice, we may use the simplified viscous operator
during the initial relaxation phase of a long run, provided this
is not already part of a production run.

%AB: we should not recommend this for production runs.
%Thus, our recommendation is: compare results with the full viscous term to
%an otherwise identical run with simplified viscosity.
%If you don't find any relevant difference, you can carry out your
%production runs with the simplified term, provided you do counter-checks
%every now and then.


% ====================================================================== %

\section{Adapting the code}


% ---------------------------------------------------------------------- %

\subsection{Adding new output diagnostics}

With the implementation of new physics and the development of new procedures
it will become necessary to monitor new diagnostic quantities that
have not yet been implemented in the code.
In the following, we describe the steps necessary to set up a new
diagnostic variable.

This is nontrivial as, in the interest of efficient communication on
multi-processor machines, the code minimizes the number of global
reduction operations by assembling all quantities that need the maximum
taken in \var{fmax}, and those that need to be summed up over all
processors (mostly for calculating mean quantities) in \var{fsum} (see
subroutine \code{diagnostic} in file \file{src/eq.f90}).

As a sample variable, let us consider \var{jbm} (the volume average
$\bigl<\jv\dot\Bv\bigr>$).
Only the module \name{Magnetic} will be affected, as you can see (the
diagnostic quantity \var{jbm} is already implemented) with
\begin{alltt}
  \prompt{unix> } grep -i jbm src/*.f90
\end{alltt}

If we pretend for the sake of the exercise that no trace of \var{jbm} was
in the code, we would need to do the following
\begin{enumerate}
\item add the variable \var{i_jbm} to the \emph{module variables} of
  \name{Magnetic} in both \file{magnetic.f90} and \file{nomagnetic.f90}:
  \begin{alltt}
  integer :: i_jbm=0
  \end{alltt}
  The variable \var{i_jbm} is needed for matching with the list of
  diagnostic variables specified in \file{print.in}.
\item in the subroutine \code{daa_dt} in \file{magnetic.f90}, declare and
  calculate the quantity \var{jb} (the average of which will be
  \var{jbm}), and call \code{sum_mn_name}
  \begin{alltt}
  real, dimension (nx) :: jb
  {\sl[\ldots]}
  if (ldiagnos) then          {\sl! only calculate if diagnostics is required}
    if (i_jbm/=0) then        {\sl! anybody asked for jbm?}
      call dot_mn(jj,bb,jb)   {\sl! assuming jj and bb are known}
      call sum_mn_name(jb,i_jbm)
    endif
  endif
  \end{alltt}
\item in the subroutine \code{rprint_magnetic} in both \file{magnetic.f90}
  and \file{nomagnetic.f90}, add the following:
  \begin{alltt}
  !
  !  reset everything in case of reset
  !  (this needs to be consistent with what is defined above!)
  !
  if (lreset) then  {\sl! need to reset list of diagnostic variables?}
    {\sl[\ldots]}
    i_jbm=0
    {\sl[\ldots]}
  endif
  !
  !  check for those quantities that we want to evaluate online
  !
  do iname=1,nname
    {\sl[\ldots]}
    call parse_name(iname,cname(iname),cform(iname),'jbm',i_jbm)
    {\sl[\ldots]}
  enddo
  {\sl[\ldots]}
  !
  !  write column where which magnetic variable is stored
  !
  {\sl[\ldots]}
  write(3,*) 'i_jbm=',i_jbm
  {\sl[\ldots]}
  \end{alltt}
\item in the subroutine \code{rprint_magnetic} in \file{nomagnetic.f90}, add
  the following (newer version of the code may not require this any more):
  \begin{alltt}
  !
  !  write column where which magnetic variable is stored
  !  idl needs this even if everything is zero
  !
  {\sl[\ldots]}
  write(3,*) 'i_jbm=',i_jbm
  {\sl[\ldots]}
  \end{alltt}
\item and don't forget to add your new variable to \file{print.in}:
  \begin{alltt}
  jbm(F10.5)
  \end{alltt}
\end{enumerate}

If, instead of a mean value, you want a new maximum quantity, you need to
replace \code{sum\_mn\_name()} by \code{max\_mn\_name()}.


% ---------------------------------------------------------------------- %

\subsection{Outputting new horizontal averages}

Currently, only the horizontally $xy$-averaged $x$ and $y$ components
of the magnetic field can be outputted. This is determined by the existence
and contents of the file \file{xyaver.in}.
New such variables can be added by using the existing averaging
procedures as examples.

% ---------------------------------------------------------------------- %

\subsection{Other averages}

There is currently the possibility to output also $xz$ and $yz$
averages. This is done by averaging first in the z-direction only, so
the result (which is available on the root processor) depends on $x$
and $y$. From these planes we calculate then (on the root processor)
the $xz$ and $yz$ averages. The energies of the so defined mean fields
are referred to as \var{bmy} and \var{bmx}, respectively.

{\it Disadvantage}: one needs to set the file \file{zaver.in} with
the entries \var{bxmxy}, \var{bymxy}, \var{bzmxy}, which produces a
rather big file \file{tmp/zaverages.dat}.


% ---------------------------------------------------------------------- %

\subsection{Adding new physics modules}

If you want to add new physics to the code, you will in many cases want to
add a new module \name{newphysics} together with the corresponding
\name{nonewphysics} module.
For a module involving a new variable, the \name{pscalar} module is a good
prototype.
The grep command
\begin{alltt}
  \prompt{unix> } grep -i pscalar src/*
\end{alltt}
gives you a good overview of which files you need to edit or add.

If you just want to add a few new terms to the equation of motion or
other evolution equations, \name{grav_z} or \name{forcing} may be a good
starting point.


% ====================================================================== %

\section{Frequently Asked Questions}

% ---------------------------------------------------------------------- %

\subsection{Compilation}

\subsubsection{Compilation stops with the cryptic error message:}
\begin{Verbatim}
f95  -O3 -u -c .f90.f90
Error : Could not open sourcefile .f90.f90
compilation aborted for .f90.f90 (code 1)
make[1]: *** [.f90.o] Error 1
\end{Verbatim}
What is the problem?

\medskip

{\em
  One of the variables for the \file{makefile} has not been set, so
  \cmd{make} expands it to the empty string.
  Most probably you forgot to specify a module in
  \file{src/Makefile.local}. One possibility is that you have upgraded
  from an older version of the code that did not have some of the modules
  the new version has.
  
  Compare your \file{src/Makefile.local} to one of the examples that
  work.
}


\subsubsection{The code doesn't compile,}
\ldots there is a problem with \var{mvar}:
\begin{Verbatim}
make start.x run.x
f95 -O4 -u -Wc,-malign-double    -c cdata.f90
Error: cdata.f90, line 71: Implicit type for MVAR
       detected at MVAR@)
[f95 terminated - errors found by pass 1]
make[1]: *** [cdata.o] Error 2
\end{Verbatim}

\medskip

{\em
  Check and make sure that \file{mkcparam} (directory
  \file{\$PENCIL_HOME/bin}) is in your path.
  If this doesn't help, there may be an {\it empty} \file{cparam.inc}
  file in your \file{src} directory. Remove \file{cparam.inc} and try again.
  (Note that \file{cparam.inc} is automatically generated.)\footnote{Wolfgang,
    I just added \file{\rm *.inc} to the \file{Makefile}.}
}


% ---------------------------------------------------------------------- %

\subsection{Running}

\subsubsection{\file{run.csh} doesn't work:}
\begin{Verbatim}
Invalid character ''' in NAMELIST input
Program terminated by fatal I/O error
Abort
\end{Verbatim}

{\em
  The string array for the boundary condition, e.g.\ \var{bcx} or
  \var{bcz} is too long. Make sure it has exactly as many elements
  as \var{nvar} is big.
}

\subsubsection{Under IRIX, I get}
\begin{Verbatim}
lib-4001 : UNRECOVERABLE library error 

Encountered during a namelist READ from unit 1
Fortran unit 1 is connected to a sequential formatted text file: "run.in"
IOT Trap
Abort
\end{Verbatim}

This is a compiler bug that has been found at least with the MIPSpro F90
compiler version 7.3.1.3m.
It has been reported to SGI.
For the time being, you will need to turn your namelist input (at least
\file{run.in} into Fortran statements, include them into a replacement
version of \file{param_io.f90}, and recompile each time you make changes.
We hope that a fixed compiler version will appear soon.


% ---------------------------------------------------------------------- %

\subsection{Visualization}

\subsubsection{\file{start.pro} doesn't work:}
\begin{Verbatim}
Reading grid.dat..
Reading param.nml..
% Expression must be a structure in this context: PAR.
% Execution halted at:  $MAIN$            104
/home/brandenb/pencil-code/runs/forced/hel1/../../../idl/start.pro
\end{Verbatim}

\medskip

{\em
  You don't have the subdirectory \file{tmp} in your IDL variable
  \var{!path}.
  Make sure you source \file{sourceme.csh}/\file{sourceme.sh}
  or set a sufficient IDL path otherwise.
}


% ====================================================================== %

\begin{thebibliography}{9}

\bibitem{2Nstorage} Williamson, J. H., J. Comp. Phys. 35, 48 (1980)
\bibitem{Lele92} Lele, S. K., J. Comp. Phys. 103, 16 (1992)
\bibitem{NS90} Nordlund, \AA., Stein, R. F., Comput. Phys. Commun. 59, 119 (1990)
\bibitem{Ref-3} Brandenburg, A., et al., J. Fluid Mech. 306, 325 (1996)
\bibitem{BNST95} Brandenburg, A., et al., Astrophys. J., 446, 741 (1995)
\bibitem{Ref-1} Brandenburg, A., in Advances in non-linear dynamos,
ed. A. Ferriz-Mas \& M. N\'u\~nez Jim\'enez (2001);
\url{http://arXiv.org/abs/astro-ph/0109497}
\bibitem{Ref-4} Brandenburg, A., Dobler, W., Astron. Astrophys. 369, 329 (2001)
\bibitem{SH88} Stanescu, D., Habashi, W. G., J. Comp. Phys. 143, 674 (1988)
\bibitem{KR80} Krause, F., R\"adler, K.-H., Mean-Field
Magneto\-hy\-dro\-dy\-na\-mics and Dynamo Theory,
Akademie-Verlag, Berlin; also Pergamon Press, Oxford (1980)
\bibitem{Ref-2} Brandenburg, A., Astrophys. J. 550, 824 (2001)

\end{thebibliography}



% ====================================================================== %
\appendix
% ====================================================================== %

\section{Timings}

In Table~\ref{Ttimescale} we list the results of timings of the code on
different machines.
Shown is (among other quantities) the wall clock time per mesh point
(excluding the ghost zones) and per full 3-stage time step.

As these results were assembled during the development phase of the code
(that hasn't really finished yet\ldots), you may not get the same numbers,
but they should give some orientation of what to expect for you specific
application on your specific hardware.
Not that the timer currently used will overflow on some machines (after
about 50 minutes), so you should not blindly trust the timings given by
the code.


% ---------------------------------------------------------------------- %
\begin{table}[htb]
  \begin{center}
    \caption{
      Wall clock time per mesh point (excluding the ghost zones)
      and per full 3-stage time step.
      The Mhd machine has 4 processors per node sharing memory;
      for easier comparison, we list the memory per CPU (i.\,e.~memory per
      node, divided by 4).
    }
    \label{Ttimescale}
    \begin{small}
    \begin{tabular}{rllrlrll}
    \toprule
   \mcc{proc(s)}
     & \mcc{machine}
             & \mcc{$\displaystyle\frac{{\mu\rm s}}{\rm pt\;\;step}$}
                    & \mcc{resol.} 
                              & \mcc{what}
                                             & \mcc{mem./proc}
                                                      & \mcc{when}&\mcc{who}\\
    \midrule
   1 & Nl3   &  19  &  $64^3$ & kinematic    &  10 Mb & 20-may-02 & AB \\
   1 & Nl3   &  30  &  $64^3$ & magn/noentro &  20 Mb & 20-may-02 & AB \\
   1 & Nq1   &  10  &  $64^3$ & magn/noentro &        & 30-may-02 & AB \\
   1 & Ukaff & 9.2  &  $64^3$ & magn/noentro &        & 20-may-02 & AB \\
   1 & Mhd   & 7.8  &  $64^3$ & magn/noentro &        & 20-may-02 & AB \\
   1 & Kabul & 4.4  & $128^3$ & magn/noentro & 130 Mb & 20-jun-02 & WD \\
   2 & Kabul & 2.5  & $128^3$ & magn/noentro &  80 Mb & 20-jun-02 & WD \\
   4 & Nq[0-3]
             & 6.8  & $256^3$ & magn/noentro & 294 Mb & 10-jun-02 & AB \\
   4 & Mhd   & 2.76 &  $64^3$ & magn/noentro &        & 30-may-02 & AB \\
   4 & Mhd   & 8.2  &  $64^2\times16$ & nomagn/entro & & 23-jul-02 & AB \\
   4 & Kabul & 1.5  & $128^3$ & magn/noentro &  47 Mb & 20-jun-02 & WD \\
   8 & Ukaff & 1.24 &  $64^3$ & magn/noentro &        & 20-may-02 & AB \\
   8 & Kabul & 1.25 & $64^2{\times}128$                                  
                              & nomagn/entro &        & 11-jul-02 & WD \\
   8 & Kabul & 0.83 & $128^3$ & magn/noentro &  28 Mb & 20-jun-02 & WD \\
   8 & Kabul & 0.87 & $256^3$ & magn/noentro & 160 Mb & 20-jun-02 & WD \\
  16 & Mhd   & 0.64 & $256^3$ & magn/noentro &  60 Mb & 22-may-02 & AB \\
  16 & Ukaff & 0.61 & $128^3$ & magn/noentro &        & 22-may-02 & AB \\
  16 & Ukaff & 0.64 & $256^3$ & magn/noentro &        & 20-may-02 & AB \\
  16 & Kabul & 0.80 & $128^3$ & magn/noentro &  16 Mb & 20-jun-02 & WD \\
  16 & Kabul & 0.51 & $256^3$ & magn/noentro &   9 Mb & 20-jun-02 & WD \\
  32 & Ukaff & 0.34 & $256^3$ & magn/noentro &        & 20-may-02 & AB \\
  32 & Ukaff & 0.32 & $512^3$ & magn/noentro &        & 20-may-02 & AB \\
  64 & Ukaff & 0.17 & $512^3$ & magn/noentro &        & 21-may-02 & AB \\
    \bottomrule
    \end{tabular}
    \end{small}
  \end{center}
\end{table}
% ---------------------------------------------------------------------- %

The machines we have used can be characterized as follows:
\begin{description}
\item[Nl3:] 500\,MHz Pentium III single CPU;
  RedHat Linux 6.2;
  256\,MB memory
\item[Nq0:] 931\,MHz Pentium III single CPU;
  RedHat Linux 7.3;
  0.5\,GB memory
\item[Nq{[1-4]}:] 869\,MHz Pentium III dual-CPU cluster;
  RedHat Linux 7.3;
  0.77\,GB memory per (dual) node
\item[Nq{[5-6]}:] 1.2\,GHz Athlon dual-CPU cluster;
  RedHat Linux 7.3;
  1\,GB memory per (dual) node
\item[Kabul:] 1.9\,GHz Athlon dual-CPU cluster;
  1\,GB memory per (dual) node;
  256\,kB cache per CPU;
  Gigabit ethernet;
  SuSE Linux 8.0;
  LAM-MPI
\item[Cincinnatus:] 1.7\,GHz Pentium 4 single CPU;
  1\,GB memory;
  256\,kB cache per CPU;
  SuSE Linux 7.3
\item[Ukaff:] SGI Origin 3000;
  400\,MHz IP35 CPUs;
  IRIX 6.5;
  native MPI
\item[Mhd:] EV6 Compaq cluster with 4 CPUs per node;
  4\,GB memory per node (i.\,e.~1\,GB per CPU)
  OSF1 4.0;
  native MPI
\end{description}

Table~\ref{Ttimescale-convsample} shows a similar list, but for a few
well-defined sample problems.

% ---------------------------------------------------------------------- %
\begin{table}[htb]
  \begin{center}
    \caption{
      Like Table~\ref{Ttimescale}, but for the versions from the
      \file{samples} directory.
    }
    \label{Ttimescale-convsample}
    \begin{small}
    \begin{tabular}{rllrlrll}
    \toprule
    \mcc{proc(s)}
       & \mcc{machine}
             & \mcc{$\displaystyle\frac{{\mu\rm s}}{\rm pt\;\;step}$}
                    & \mcc{resol.} 
                                    & \mcc{mem./proc}
                                                    & \mcc{when}&\mcc{who}\\
    \midrule
      \multicolumn{7}{c}{\emph{conv-slab}}\\
    \midrule
        1 & Mhd         & 6.45 &  $32^3$ &    4 Mb & 23-jul-02 & wd \\
        1 & Cincinnatus & 4.82 &  $32^3$ &    3 Mb & 23-jul-02 & wd \\
        1 & Cincinnatus & 11.6 &  $64^3$ &   14 Mb & 23-jul-02 & wd \\
        1 & Cincinnatus & 20.8 & $128^3$ &   93 Mb & 23-jul-02 & wd \\
        1 & Kabul       & 3.91 &  $32^3$ &         & 23-jul-02 & wd \\
        1 & Kabul       & 3.88 &  $64^3$ &         & 23-jul-02 & wd \\
        1 & Kabul       & 4.16 & $128^3$ &   93 Mb & 23-jul-02 & wd \\
    \midrule
      \multicolumn{7}{c}{\emph{conv-slab-flat}}\\
    \midrule
        1 & Kabul       & 3.02 &  $128^2{\times}32$
                                         &   29 Mb & 23-jul-02 & wd \\
        2 & Kabul       & 1.81 &  $128^2{\times}32$
                                         &   18 Mb & 23-jul-02 & wd \\
        4 & Kabul       & 1.03 &  $128^2{\times}32$
                                         &   11 Mb & 23-jul-02 & wd \\
        8 & Kabul       & 0.87 &  $128^2{\times}32$
                                         &    9 Mb & 23-jul-02 & wd \\
    \bottomrule
    \end{tabular}
    \end{small}
  \end{center}
\end{table}
% ---------------------------------------------------------------------- %


% ====================================================================== %


\section{Some specific initial conditions}

\subsection{Random magnetic fields: \var{initaa='gaussian-noise'}}

The $\Av$-vector is set to normally distributed, uncorrelated(?) random
numbers in all meshpoints for all three components.
The power spectrum of
$\Av$ increases then quadratically with wavenumber $k$ (without cutoff)
and the power spectrum of $\Bv$ increases like $k^4$.

% ---------------------------------------------------------------------- %

\subsection{Beltrami fields: \var{initaa='Beltrami-z'}}

\begin{equation}
%\Av=\pmatrix{\cos z\cr\sin z\cr0}
\Av=(\cos z,\;\sin z,\;0)
\label{Beltrami}
\end{equation}

% ---------------------------------------------------------------------- %

\subsection{Magnetic flux rings: \var{initaa='fluxrings'}}
\label{fluxrings}

This initial condition sets up two interlocked thin magnetic tori
(i.\,e.~thin, torus-shaped magnetic flux tubes).
One torus of radius $R$ lying in the plane $z=0$ can be described in
cylindrical coordinates by the
vector potential
\begin{equation} \label{Av-flux-ring-cyl}
  \Av = 
  \Phi_{\rm m}
  \begin{pmatrix}
    0\\ 0\\ -\Heavi(r{-}R) \delta(z)
  \end{pmatrix} \; ,
\end{equation}
resulting in a magnetic field
\begin{equation}
  \Bv = 
  \Phi_{\rm m}
  \begin{pmatrix}
    0\\ \delta(r{-}R) \delta(z)\\ 0
  \end{pmatrix} \; .
\end{equation}
Here $\Phi_{\rm m}$ is the magnetic flux through the tube,
$\Heavi(x)$ denotes the Heaviside function, and
\begin{equation} \label{Heavi-Dirac}
 \delta(x) = \Heavi'(x)
\end{equation}
is Dirac's delta function.

Any smoothed versions of $\Heavi(x)$ and $\delta(x)$ will do, as long as
the consistency condition (\ref{Heavi-Dirac}) is satisfied.
E.\,g.~the pairs
\begin{equation}
  \delta_\varepsilon(x)
  = \frac{1}{\sqrt{2\pi\varepsilon^2}} e^{-\frac{x^2}{2\varepsilon^2}} \; ,
  \quad
  \Heavi_\varepsilon(x)
  = \frac{1}{2} \left( 1 + \erf\frac{x}{\sqrt{2}\varepsilon} \right)
\end{equation}
or
\begin{equation}
  \delta_\varepsilon(x)
  = \frac{1}{2\varepsilon}\frac{1}{\cosh^2\frac{x}{\varepsilon}} \; ,
  \quad
  \Heavi_\varepsilon(x)
  = \frac{1}{2} \left( 1 + \tanh\frac{x}{\varepsilon} \right)
\end{equation}
are quite popular.

In Cartesian coordinates, the vector potential (\ref{Av-flux-ring-cyl})
takes the form
\begin{equation} \label{Av-flux-ring-cart}
  \Av =
  \Phi_{\rm m}
  \begin{pmatrix}
    0\\ 0\\ -\Heavi \left( \sqrt{x^2{+}y^2}{-}R \right) \delta(z)
  \end{pmatrix} \; .
\end{equation}


% ---------------------------------------------------------------------- %

\subsection{Vertical stratification}

Gravity, $\bf{g}=-\nab\Phi$, is specified in terms of a potential
$\Phi$. In slab geometry, $\Phi=\Phi(z)$, so ${\bf g}=(0,0,g_z)$ and
$g_z=-\dd\Phi/\dd z$.

Use \var{grav_profile='const'} (which is already the default)
together with \var{gravz}$=-1$ to get
\begin{equation} \label{constgrav-gravz-init}
  \Phi=(z-z_\infty)(-g_z),\quad g_z=-1.
\end{equation}
Use \var{grav_profile='linear'} to get
\begin{equation} \label{disc-gravz-init}
  \Phi={\textstyle\frac{1}{2}}(z^2-z_\infty^2)\Omega^2,\quad g_z=-\Omega^2z
\end{equation}
where (currently) the parameter \var{gravz} is used in place of
$-\Omega^2$; this form of the gravitational potential is commonly used for
accretion discs.

The value of $z_\infty$ is determined such that $\varrho=\varrho_0$ and
$c_{\rm s}^2=c_{\rm s0}^2$ at $z=z_{\rm ref}$. This depends on the
values of $\gamma$ and the polytropic index $m$ (see below).

\subsubsection{Isothermal atmosphere}

Here we want $c_{\rm s}=c_{\rm s0}=\mbox{const}$.
Using \code{initlnrho='isothermal'} means
\begin{equation} \label{constgrav-lnrho-init}
  \ln\frac{\varrho}{\varrho_0}
  = -\gamma \frac{\Phi}{c_{\rm s0}^2} \; .
\end{equation}
The entropy is then initialized to
\begin{equation} \label{constgrav-ss-init}
  \frac{s}{c_{\rm p}}
  = (\gamma{-}1) \frac{\Phi}{c_{\rm s0}^2} \; .
\end{equation}
In order that $\varrho=\varrho_0$ and $c_{\rm s}^2=c_{\rm s0}^2$ at
$z=z_{\rm ref}$, we have to choose $z_\infty=z_{\rm ref}$.

\subsubsection{Polytropic atmosphere}

For a polytropic equation of state, $p=K\varrho^\Gamma$, where generally
$\Gamma\neq\gamma$, we can write
\begin{equation}
  -\nab h+T\nab s
  = -\frac{1}{\varrho}\nab p
  = -\nab\left(\frac{\Gamma K}{\Gamma{-}1}\varrho^{\Gamma{-}1}\right)
\equiv-\nab\tilde{h},
\end{equation}
where we have introduced a pseudo enthalpy $\tilde{h}$ as
\begin{equation}
  \tilde{h} = \frac{\Gamma K}{\Gamma{-}1}\varrho^{\Gamma{-}1}
  =\left[\left(1-\frac{1}{\gamma}\right)
    \left/\left(1-\frac{1}{\Gamma}\right)\right.\right]\,h\; .
\end{equation}
Obviously, for $\Gamma=\gamma$, the pseudo enthalpy $\tilde{h}$ is
identical to $h$ itself.
Instead of specifying $\Gamma$, one usually defines the polytropic
index $m=1/(\Gamma{-}1)$. Thus, $\Gamma=1+1/m$, and
\begin{equation}\label{hhtilde}
  \tilde{h}=(m{+}1)\left(1-\frac{1}{\gamma}\right)\,h
\end{equation}

This is consistent with a fixed entropy dependence,
where $s$ only depends on $\varrho$ like
\begin{equation}
  \frac{s}{c_{\rm p}} = \left( \frac{\Gamma}{\gamma} - 1 \right)
                        \ln\frac{\varrho}{\varrho_0} \; ,
\end{equation}
and implies that
\begin{equation}
  \ln \frac{c_{\rm s}^2}{c_{\rm s0}^2}
  = (\Gamma{-}1) \ln\frac{\varrho}{\varrho_0} \; .
\end{equation}

For hydrostatic equilibrium we require
$\tilde{h}+\Phi=\tilde{h}_0=\const$.
For gravity potentials that vanish at infinity, we can have
$\tilde{h}_0\neq0$, i.e.\ a finite pseudo enthalpy at infinity.
For $g_z=-1$ or $g_z=-z$, this is not the case, so we put
$\tilde{h}_0=0$, and therefore $\tilde{h}=-\Phi$.
Using $c_{\rm s}^2=(\gamma{-}1)h$ together with (\ref{hhtilde}) we find
\begin{equation}
  c_{\rm s}^2 = -\frac{\gamma}{m{+}1}\,\Phi.
\end{equation}
In order that $\varrho=\varrho_0$ and $c_{\rm s}^2=c_{\rm s0}^2$ at
$z=z_{\rm ref}$, we have to choose (remember that $g_z$ is normally negative!)
\begin{equation}\label{zinfty}
  z_\infty = z_{\rm ref} + (m{+}1) \frac{c_{\rm s0}^2}{-\gamma g_z}
  \quad\mbox{for \var{grav_profile='const'}},
\end{equation}
and
\begin{equation}\label{zinfty}
  z_\infty^2
  = z_{\rm ref}^2
    + (m{+}1) \frac{c_{\rm s0}^2}{{\textstyle\frac{1}{2}}\gamma\Omega^2}
  \quad\mbox{for \var{grav_profile='linear'}}.
\end{equation}
Thus, when using \var{initlnrho='polytropic\_simple'} we calculate
\begin{equation}
  \ln \frac{c_{\rm s}^2}{c_{\rm s0}^2}
  =\ln\left[-\frac{\gamma\Phi}{(m{+}1)c_{\rm s0}^2}\right]
\end{equation}
and so the stratification is given by
\begin{equation}
  \ln\frac{\varrho}{\varrho_0}
  = m \ln \frac{c_{\rm s}^2}{c_{\rm s0}^2} \; ,\quad
  %
  \frac{s}{c_{\rm p}}
  = \left(\frac{\Gamma}{\gamma}-1\right)
    m\ln \frac{c_{\rm s}^2}{c_{\rm s0}^2} \; .
\end{equation}


\subsubsection{Changing the stratification}

Natural: measure length in units of $c_{\rm s0}^2/g_z$.
Can increase stratification by moving $z_{\rm top}$ close to $z_\infty$.
Disadvantage: in the limit of weak stratification, the box size will
be very small (in nondimensional units).

Box units: measure length in units of $d$.
Can increase stratification by increasing $g_z$ to
$g_{\max}$, which can be obtained by putting $z_{\rm top}=z_\infty$
in (\ref{zinfty}), so
\begin{equation}\label{zinfty}
  g_{\max}=\frac{m{+}1}{\gamma}\,\frac{c_{\rm s0}^2}{z_{\rm top}-z_{\rm ref}}.
\end{equation}
For $m=1$, $\gamma=5/3$, $z_{\rm top}=1$, and $z_{\rm ref}=0$, for
example, we have $g_{\max}=6/5=1.2$.

Gravitational box units: measure speed in units of $\sqrt{g_z d}$.
The limit of vanishing stratification corresponds to
$c_{\rm s0}\rightarrow\infty$. This seems optimal if we want
to approach the Boussinesq case.


% ====================================================================== %

\section{Some reference data}
\label{S-ref-data}

For reference purposes we document here some results obtained with various
samples of the code.

% ---------------------------------------------------------------------- %

\subsection{Three-layered convection model}

In Sect.~\ref{S-getting-started} we have shown the early stages of the
convection model located in \file{samples/conv-slab}.
To arrive at fully developed convection, you will need to run the code for
a larger number of time steps.
Figure~\ref{Fig-pvert2} shows the vertical profiles of four basic
quantities at time $t=50$.
Figure~\ref{Fig-evol} shows the time evolution of rms and maximum
velocity for the model for $0<t<50$.

% ---------------------------------------------------------------------- %
\begin{figure}[hbtp]
  \centering
  \includegraphics%
    [width=1\textwidth,keepaspectratio]%
    {pvert2}
  \caption{Like in Fig.~\ref{Fig-pvert0}, but at time $t=50$.
  }
  \label{Fig-pvert2}
\end{figure}
% ---------------------------------------------------------------------- %

% ---------------------------------------------------------------------- %
\begin{figure}[hbtp]
  \centering
  \includegraphics%
    [width=0.7\textwidth,keepaspectratio]%
    {evol}
  \caption{Time evolution of rms and maximum velocity for the model
    \file{samples/conv-slab}.
     Plots of this type can be produced by running the IDL script
     \file{evol.pro}.
  }
  \label{Fig-evol}
\end{figure}
% ---------------------------------------------------------------------- %

Figures~\ref{Fig-hsection2} and \ref{Fig-vsection2} show vertical and
horizontal sections for time $t=50$.

% ---------------------------------------------------------------------- %
\begin{figure}[hbtp]
  \centering
  \includegraphics%
    [width=0.8\textwidth,height=0.65\textheight,keepaspectratio]%
    {hsect2}
  \caption{Horizontal section $z=0.352$ at $t=50$.
    Left: velocity field.
    Right: entropy (color coded) and density (isocontours).
    Plots of this type can be produced by running the IDL scripts
    \file{hsections.pro})
  }
  \label{Fig-hsection2}
\end{figure}
% ---------------------------------------------------------------------- %

% ---------------------------------------------------------------------- %
\begin{figure}[hbtp]
  \centering
  \includegraphics%
    [width=0.8\textwidth,height=0.65\textheight,keepaspectratio]%
    {vsect2}
  \caption{Vertical section $y=0.516$ at $t=50$.
    Left: velocity field.
    Right: entropy (color coded) and density (isocontours).
    Plots of this type can be produced by running the IDL scripts
    \file{vsections.pro}) or \file{vsections2.pro}).
  }
  \label{Fig-vsection2}
\end{figure}
% ---------------------------------------------------------------------- %


% ====================================================================== %


\printindex


\ \vfill\bigskip\noindent{\footnotesize\it
$ $Id: manual.tex,v 1.69 2002-07-24 11:46:03 brandenb Exp $ $}


\end{document}

%%% Please leave this for Emacs [wd]:

%% Local Variables:
%% ispell-check-comments: t
%% Local IspellDict: american
%% End:
% LocalWords:  SPH CVS tex wd MHD makeindex pdflatex MPI Dobler nonperiodic src
% LocalWords:  nonmagnetic nomagnetic IDL DX OpenDX csh Perl Perl Cygwin tgz mv
% LocalWords:  tarball unix somewhere cd gunzip xf mhd passwd CVSROOT cshrc sh
% LocalWords:  setenv cvs cvspass code's dP sourceme lnsrc mkdir tmp tmp struct
% LocalWords:  isotrop keepaspectratio spher gravz README cparam idl dx nograv
% LocalWords:  nohydro nodensity noentropy rhs noforcing rr noglobal fft FFT io
% LocalWords:  nofft dist mpicomm nompicomm DFUNDERSCORE nodebug mkfile var dat
% LocalWords:  interoperability rall bb aa jj Pvwave param nml param nml param
% LocalWords:  stdout oum zaver bxmz bymz nl timestr lp ip ip iper iperx ztop
% LocalWords:  hcond whcond mpoly isothtop ampl init urand cs nt dt cdt CFL bc
% LocalWords:  cdtv Alfv isave isave iorder iorder Kutta dsnap dsnap dvid dtmin
% LocalWords:  tinit tdamp dampu dampuext rdamp wdamp ivisc cdiffrho Fheat tvid
% LocalWords:  wcool iforce relhel tsnap hystrostatic isothermality initaa jbm
% LocalWords:  meshpoints jb mn rprint xy Compaq Mb resol linux magn noentro nq
% LocalWords:  ukaff jun sourcefile kbd env rm dfn MNRAS url html dobler Exp ic
% LocalWords:  ODEs PDEs iterform ccccccc pscalar nopscalar urms rhom Lxyz xyz
% LocalWords:  cvsid lperi lwrite lnowrite inituu ampluu widthuu uu initlnrho
% LocalWords:  widthlnrho piecew zref ampllnrho const initss linprof pertss ss
% LocalWords:  khor gaussian hor fluxtube fluxlayer Bx Bz fluxrings fluxrings
% LocalWords:  Alfven circ amplaa fring Iring Rring wr epsilonaa widthaa nvar
% LocalWords:  kx ky kz wavenumbers lpress equil initlncc ampllncc lncc qshear
% LocalWords:  tmax itorder iwig ialive bcx bcy bcz ce diffrho kinflow ABC diff
% LocalWords:  ff kfountain nomagn entro jul cdata mkcparam inc Phys Lele al hy
% LocalWords:  Nordlund Comput Commun Astrophys Ferriz Mas enez Stanescu adler
% LocalWords:  Habashi dro dy na mics Akademie polytropes nondimensional mvar
% LocalWords:  Boussinesq Wc newphysics nonewphysics fmax fsum daa nx ldiagnos
% LocalWords:  endif lreset iname nname cname cform enddo Pentium GHz Athlon GB
% LocalWords:  SuSE SGI IRIX Tru noshear RedHat ethernet ds pvert umax ssm dtc
% LocalWords:  rms getconf sourced substep perldoc lmpi llam FC FFLAGS LDMPI mk
% LocalWords:  SunOS UNICOS UX MPP AIX xyaver bmy bmx bxmxy bymxy bzmxy conv dz
% LocalWords:  evol hsect hsections vsect vsections vsections texinfo nxgrid ke
% LocalWords:  nygrid nzgrid ccc widthss ttransient brandenb Nils Pariev tcsh ls ln
% LocalWords:  cincinnatus CEST mx mz lnrho pf nprocy ncpus nprocz
% LocalWords:  nprocx MIPSpro
