#!/bin/sh
# CVS: $Id$
#                       pc_run
#                      ---------
#   Run src/run.x (timestepping for src/run.x).
#   Run parameters are set in run.in.
#
# Run this script with sh:
#PBS -S /bin/sh
#$ -S /bin/sh
#@$-s /bin/sh
#
# Join stderr and stout:
#$ -j y -o run.log
#@$-eo
#@$-o run.log
#
# Work in submit directory (SGE):
#$ -cwd
# Work in submit directory (PBS):
[ -e "$PBS_O_WORKDIR" ] && cd $PBS_O_WORKDIR
# Work in submit directory (SUPER-UX's nqs):
[ -e "$QSUB_WORKDIR" ] && cd $QSUB_WORKDIR

# Common setup for start.csh, run.csh, start_run.csh:
# Determine whether this is MPI, how many CPUS etc.
# This implicitly sources pc_functions.sh too.
debug=yes
. pc_config.sh

# Prevent code from running twice (and removing files by accident)
check_not_locked
# If local disc is used, write name into $datadir/directory_snap.
# This will be read by the code, if the file exists.
# Remove file, if not needed, to avoid confusion.
prepare_scratch_disk
#  If we don't have a data subdirectory: stop here (it is too easy to
#  continue with an NFS directory until you fill everything up).
check_datadir
# If the file NOERASE exists, the old directories are not erased
#   (start.x also knows then that var.dat is not created)
prepare_datadir

# If local disk is used, copy executable to $SCRATCH_DIR of master node
distribute_binary src/start.x

# Run start.x timestamping and timing appropriately
pencil_code_start
if [ $start_status -ne 0 ]; then
  echo "Starting failed.  Exiting..."
  final_copy_snapshots
  tidy_scratch_disk
  exit $start_status
fi

# Prevent code from running twice (and removing files by accident)
create_lock

first_job=yes
job_finished=no
until [ "$job_finished" = "yes" ]  # Allow NEWDIR job migration
do
  #  If necessary, distribute var.dat from the server to the various nodes
  [ ! "$first_job" = "yes" ] && distribute_data_to_nodes
  first_job=no
  run_finished=no
  until [ "$run_finished" = "yes" ]  # Allow RERUN code restart
  do
    # Clean up control and data files
    tidy_rundir
    # On machines with local scratch directory, initialize automatic
    # background copying of snapshots back to the data directory.
    background_copy_snapshots
    # Copy output from `top' on run host to a file we can read from login server
    background_remote_top
    # If necessary copy executable to $SCRATCH_DIR of master node
    distribute_binary src/run.x

    # Write $PBS_JOBID to file (important when run is migrated within the same job)
    save_jobid "RUN STARTED "
    # Run run.x timestamping and timing appropriately
    pencil_code_run
    # Write $PBS_JOBID to file (important when run is migrated within the same job)
    save_jobid "RUN FINISHED"

    check_RERUN
  done

  # On machines with local scratch disc, copy var.dat back to the data directory
  final_copy_snapshots
  # Kill all backgrounded copy-snapshots
  unbackground_copy_snapshots

  check_reference_data
  check_NEWDIR
done

remove_lock
tidy_scratch_disk

# Shut down lam if we have started it
[ "$booted_lam" = "yes" ] && lamhalt
exit $run_status                # propagate status of mpirun

